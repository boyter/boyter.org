<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Golang-Syd 25th May 2023</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/sky.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Building a code search index in Go</h1>
				</section>

				<section>
					<h2>Who are you?</h2>
					<p>
					"Officially" technical lead/principle at Kablamo but a "code monkey" at heart.</p>
					<p>I blog <a href="https://boyter.org/">boyter.org</a> I free software <a href="https://github/boyter/">github/boyter/</a> I run <a href="https://searchcode.com/">searchcode.com</a> also on the twitter <a href="https://twitter.com/boyter">@boyter</a> activitypub <a href="https://honk.boyter.org/boyter">@boyter@honk.boyter.org</a></p>
				</section>


				<section>
					<h2>searchcode.com</h2>
					<p>IMAGE_HERE</p>
					<aside class="notes">So I run searchcode.com, and its iteration over the last 10 years has been from PHP to Python almost to Java and finally to Go.

The whole time that has happened one thing has been constant, which was the use of the index engine, which was provided using Sphinx Search and then a forked version called Manticore.

This made me feel like a bit of a fraud, how can I claim to be a search guy without using my own index. So after the first covid lockdown in 2020, I was hiking with a mate I decided I would build my own index.

Searchcode itself indexes about 75 billion lines of code across 40 million projects pulled from github, gitlab, bitbucket, codeberg, sr.ht and such. Thats about 120 million documents although it rises and falls.

It handles about 22 RPS mostly through the api, with some portion of those being search queries and the remainder being code view queries, although it does burst much higher from time to time. It works out being about 2.6 million requests a day.</aside>
				</section>

				<section>
					<h2>Search Lifecycle</h2>
					<img src="./img/index.png" style="border: none;" />
					<aside class="notes">
So what is an index?
In short, its something you feed in queries, and get back matching unique id's in some sort of order.
There are a lot of bits that go into a search engine, crawlers, indexers, the index, query parsers, 
data storage, etc... but its the index thats considered the "cool" thing to work on.</aside>
				</section>

				<section>
					<h2>Why Go?</h2>
					<ul>

					</ul>
				</section>



				<section>
									<h2>Optimise</h2>
<pre><code style="font-size: 10px; line-height: 1em;">┌──────────────────┐    ┌───────────────────────────────────────────────────────────────────┐
│      bucket      │───▶│                                                                   │
└──────────────────┘    │ 0011100000000000000000000000000011010010000000000000010000111111  │
                        │ 0000100000000110001000000000000000000000001010001000001000000000  │
                        │ 0010000000000000000000000000000001010001111111110000010100111111  │
                        │ 0000100011010000000000000000000000000000001010001000000110000000  │
                        │ 1100011000000001111111010100100010000000000000010000000000100100  │
                        │ 0000000000000000000000000000000000000001111111110000000000000000  │
                        │ 1000011000100001111111010100000010000000000000010000000000100100  │
                        │ 0000000000000000000000000000000000000001111111110000000000000000  │
                        │ 0000000000000010000000000011000000001000000000000000000000001000  │
                        │ 1111111000000000000000000000001000010000010000000000000000011000  │
                        │ 1111111111111111000000000011000000000000000000100010000000000000  │
                        │ 1111111000000000000000000000001000010000010000010000000000001000  │
                        │ 0000000000000000000000000000000000111110000000000000000000000000  │
                        │ 0000000001100000110000001000000000000000000001000000101001000000  │
                        │ 0000000000000000000100000000000000111110000000000000110000010000  │
                        │ 0000000000100001110000001000000001000000000000000000101001111111  │
                        │                                                                   │
                        └───────────────────────────────────────────────────────────────────┘
</code></pre>
					<aside class="notes">The next step is to optimise this to not waste memory. In searchcode its done by packing 64 documents into a bloom filter block or bucket. 

So if a bloom filter had 16 bits, we keep 16 uint64's in a slice.

It would look like what you see. This ensures we are optimally using the space. Because we pack 64 documents into each bucket we end up using a single bit per location in the bloom filter.</aside>
				</section>

				<section>
					<h2>Deterministic Keys</h2>
<pre><code style="font-size: 10px; line-height: 1em;">
┌──────────────────┐   ┌──────────────────┐   ┌──────────────────┐
│     caisson      ├─┬▶│  shard 512       ├┬─▶│     bucket-1     │
└──────────────────┘ │ └──────────────────┘│  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     ├─▶│     bucket-2     │
                     │                     │  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     └─▶│     bucket-3     │
                     │                        └──────────────────┘
                     │                                            
                     │                                            
                     │ ┌──────────────────┐   ┌──────────────────┐
                     └▶│  shard 2048      ├┬─▶│     bucket-1     │
                       └──────────────────┘│  └──────────────────┘
                                           │                      
                                           │  ┌──────────────────┐
                                           ├─▶│     bucket-2     │
                                           │  └──────────────────┘
                                           │                      
                                           │  ┌──────────────────┐
                                           └─▶│     bucket-3     │
                                              └──────────────────┘
</code></pre>
					<aside class="notes">In searchcode its a little more in depth because it actually changes the size of the bloom filters based on the size of the document its indexing.

What happens is when a document is indexed, it breaks it into unique trigrams, and then finds a bloom filter where it will be stored with a target bit density. If the document has a small amount of trigrams it ends up in a smaller bloom filter of say 256 bits, and if larger it goes into a larger one up to 4096.

When the full 64 documents have been added to a bucket then in the case of a 256 bit bloom filter another 256 uint64's are appended on the end.

Where shards represent a different bloom filter size, say 512 of 2048 bits, and buckets exist as a single uint64 slice in a shard. They are split out logiclly here to help understanding.
					</aside>
				</section>


				<section>
					<h2>Deterministic Keys</h2>
<pre><code style="font-size: 10px; line-height: 1em;">
// Trigrams given input splits according to trigram rules
// where we want to be as efficient as possible
func (ci *CaissonIndex) Trigrams(text string) []string {
    var runes = []rune(text)

    if len(runes) <= 2 {
        return []string{}
    }

    ngrams := make([]string, len(runes)-2)

    for i := 0; i < len(runes); i++ {
        if i+3 < len(runes)+1 {
            ngram := runes[i : i+3]
            ngrams[i] = string(ngram)
        }
    }

    return ngrams
}
</code></pre>
					<aside class="notes">Interesting fact, in profiling the single biggest bottleneck in indexing is the trigram code. Which I include here. If someone wants to profile and improve performance on it I would really appreciate it. It dominiates the indexing approach because the bit setting is close to free from a CPU point of view.</aside>
				</section>


				<section>
					<h2>Reaction</h2>
					<img src="./img/abuse.jpg" style="border: none;" />
				</section>

				<section>
					<h2>Reaction 2</h2>
					<blockquote>the ethical thing to do is to go take your computer, make sure to pop open every single case, plug them in so you can make sure everything gets nice and fried, then give them all a long, long, long shower.</blockquote>
				</section>




				
				<section>
					<h2>GOPATH + Monorepo</h2>
					<p>Exploit GOPATH for multiple entry points into application.</p>
					<pre><code style="font-size: 16px;">.
├── assets
│   ├── imageproxy
│   │   └── main.go
│   ├── load
│   │   └── main.go
│   ├── merge
│   │   ├── audio
│   │   │   └── main.go
│   │   ├── bulk
│   │   │   └── main.go
│   │   ├── cleanup
│   │   │   └── main.go
│   │   ├── oldvideo
│   │   │   └── main.go
│   │   ├── photo
│   │   │   └── main.go
│   │   ├── video
│   │   │   └── main.go
│   │   └── wvideo
│   │       └── main.go
│   ├── transcodeFinished
│   │   └── commandline
│   │       └── main.go
│   └── transcodeStart
│       └── commandline
│           └── main.go
					</code></pre>
				</section>

				<section>
					<h2>Background Jobs</h2>
					<ul>
						<li>Load. Taxonomy. Graceful degrade. Restore.</li>
						<li>Merge's.</li>
						<li>Transcode Start/End.</li>
						<li>Image Resize, watermark.</li>
						<li>Many one off jobs.</li>
						<li>Lambda?</li>
						<li>Go memory usage a massive win.</li>
					</ul>
				</section>

				<section>
					<h2>Go for S3 copy</h2>
					<p>Excellent with SQS support. But have to code own multipart.</p>
<pre><code style="font-size: 16px;">
for _, sqsmsg := range messages.Messages {
	// We don't want to wait for these to finish anymore but let them run in the background
	// and finish whenever they are done and naturally exit. As such no need for a waitgroup
	// here anymore
	go func(sqsmsg *sqs.Message) {
</code></pre>
				</section>

				<section>
					<h2>Go Image Resizing</h2>
					<ul>
						<li>Don't do it at runtime</li>
						<li>Too slow! Watermarking.</li>
						<li>Moved to pre-generating and storing.</li>
						<li>API passes images though. Logging.</li>
						<li>Thumbor is pretty good</li>
					</ul>
				</section>

				<section>
					<h2>Clipping</h2>
					<img src="./img/2.png" style="border: none;" />
					<ul>
						<li>mediainfo, ffmpeg (mxf, mov, mp4).</li>
						<li>Disk caching/issue.</li>
						<li><a href="https://boyter.org/posts/media-clipping-using-ffmpeg-with-cache-eviction-2-random-for-disk-caching-at-scale/">2 random eviction (woo!)</a></li>
						<li>AWS Transcode? Speed/Cost.</li>
					</ul>
				</section>

				<section>
					<h2>Clipping In Action</h2>
					<p>Network bound. T3 burstable network really helps!!</p>
					<img src="./img/3.png" style="border: none;" />
				</section>


				<section>
					<h2>Glacier</h2>
					<p>Annoying when many can request. Store in DB and on event update all matches. Expire after 24 hours. Hard to predict expiration.</p>
				</section>

				<section>
					<h2>Really Helpful</h2>
					<p>Have an endpoint that exposes <b>most</b> environment variables.</p>

<pre><code style="font-size: 16px;">{
  "environment": {
    "AppEnvironment": "PROD",
    "AudioMasterBucket": "archives.master.audio",
    "AudioProxyBucket": "archives.proxy.audio",
    "AwsRegion": "ap-southeast-2",
    "DownloadExpiryMinutes": 1440,
    "ElasticEndpoint": "https://elastic-archives.content/",
    "FrontendEndpoint": "https://archive.content",
    "HttpTimeoutSeconds": 20,
    "LandingBucket": "archives.landing",
    "MetadataBucket": "archives.records.prod",
    "PhotoBucket": "archives.photo",
    "PhotoBucketProxy": "archives.proxy.photo",
    "PortNumber": 8080,
    "SystemEnvironment": "Archive",
    "SystemEnvironmentDisplayName": "Archive",
    "UploadExpiryMinutes": 1440,
    "VideoMasterBucket": "archives.master.video",
    "VideoProxyBucket": "archives.proxy.video"
  }
}</code></pre>

				</section>

				<section>
					<h2>What would we change?</h2>

					<p>AWS Changes, Fargate (CPU), Private API-Gateway, Server-less Aurora, Bucket cleaning, Instance types R5</p>
					<p>Taxonomy storage.</p>
					<p>Probably more lambda. 15 min timeout.</p>
					<p>S3 key names. Maybe GORM. Proxy!</p>
				</section>

				<section>
					<h2>Results</h2>
					<img src="./img/5.png" style="border: none;" />
					<ul>
						<li>Outages 0. Previously days/weeks.</li>
						<li>976 audio master retrievals</li>
						<li>4,008 video master retrievals. Glacier.</li>
						<li>16,014 audio proxies played</li>
						<li>157,281 video proxies played (28,469 in May)</li>
						<li>593,085 searches performed</li>
						<li>Average search time ~100 ms</li>
					</ul>
					<p>GA Jan. Culture change.</p>
				</section>

				<section>
					<h2>Results Continued</h2>

					<ul>
						<li>3 months to production cut-over. Turn off.</li>
						<li>132 TB data though API (so far)</li>
						<li>1 PB of video data in S3 / Glacier</li>
						<li>40 TB of audio data in S3</li>
						<li>16,000 images</li>
						<li>~327 days of video watching</li>
						<li>Some joker... 60x700 GB videos in one hour.</li>
						<li>Importing other systems.</li>
						<li>On time + budget!</li>
					</ul>
				</section>

				<section>
					<h2>Thank You!</h2>

					<p>Presentation located at <a href="https://boyter.org/static/golang-syd-25th-may/">https://boyter.org/static/golang-syd-25th-may/</a> or just go to boyter.org and I will link it up tomorrow.</p>
				</section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
