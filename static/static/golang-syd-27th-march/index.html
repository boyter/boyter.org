<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Golang-Syd 25th May 2023</title>

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/black.css">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="lib/css/zenburn.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h1>searchcode.com's SQLite database is probably bigger than yours</h1>
				<code>-rw-r--r-- 1 searchcode searchcode 6.4T Feb 17 04:30 searchcode.db</code>
				<aside class="notes">So yeah... as it says the database is probably bigger than yours..</aside>
			</section>

			<!-- <section>
					<h2>Who are you?</h2>
					<p>
					"Officially" technical lead/principle at Kablamo but a "code monkey" at heart.</p>
					<p>I blog <a href="https://boyter.org/">boyter.org</a> I free software <a href="https://github/boyter/">github/boyter/</a> I run <a href="https://searchcode.com/">searchcode.com</a> also on the twitter <a href="https://twitter.com/boyter">@boyter</a> activitypub <a href="https://honk.boyter.org/boyter">@boyter@honk.boyter.org</a></p>
					<aside class="notes">Not going to bore you too much with who I am because you don't care.
					
					Aside, I was going to do a talk about how you can destroy the fediverse with a few lines of code... then thought better of it. If you want that  in the future go hassle Chewy or Katie.
					</aside>
				</section> -->


			<section>
				<img src="./img/searchcode.png" height="500px;" style="border: none;" />
				<aside class="notes">I have talked about searchcode.com before, and the talks will continue until morale
					improves.

					Seriously though its where I get to try all the crazy ideas I have at scale. Also I promise not to
					add any LLM or AI content to this, we are going old school baby.
				</aside>
			</section>

			<section>
				<section>
					<h2>History</h2>
					<img src="./img/history.png" height="500px;" style="border: none;" />
					<aside class="notes">The constant between everything till now was the use of MySQL as the storage
						layer. The reasons for using it initially was it was there, I knew how to work it and it would
						scale along with my needs fairly well. So what changed? If you look at my previous choices you
						will see there is in general a move to reducing the number of dependencies. The older and more
						crusty I get the more I appreciate having a single binary I can just deploy. Single binary
						deploys are very simple to reason about.
					</aside>
				</section>
			</section>




			<section>
				<h2>SQLite "database is locked"</h2>
				<pre><code style="font-size: 14px; line-height: 1em;">dbRead, _ := connectSqliteDb("dbname.db")
defer dbRead.Close()
dbRead.SetMaxOpenConns(runtime.NumCPU())

dbWrite, _ := connectSqliteDb("dbname.db")
defer dbWrite.Close()
dbWrite.SetMaxOpenConns(1)
</code></pre>

				<aside class="notes">
					So given our trigram terms we now need to index them. There are a few ways to do this. Lets walk
					through a few.

					A posting list is the slice of struct or int64 containing the document's have that term.

					So "set" is found inside documents 1,77 and 345

					A positional index is one that stores where the term was found in the document.

					So "set" as position 5 and 56 inside document 77

					This is really useful for phrase searches and ranking.
					In theory you can then use the index to reconstruct the document entirely. One catch with this is
					that your index becomes larger than the thing you are indexing.

					Done simply these are a bit of code you can had over to your cousin or most junior developer.

					Skip lists are something you end up needing to implement because when searching multiple terms you
					look for
					the intersection of multiple posting lists and it speeds things up and something you need to add to
					scale this approach.

					They are an interesting data structure worth looking up on wikipedia. When you start adding
					compression using ellias phano to reduce the size they quickly become complex, and it becomes easy
					to tank your performance.


				</aside>
			</section>

			<section>
				<h2>SQLite "database is locked"</h2>
				<pre><code style="font-size: 14px; line-height: 1em;">func connectSqliteDb(location, name string) (*sql.DB, error) {
	db, err := sql.Open("sqlite", fmt.Sprintf("%s.db?_busy_timeout=5000", path.Join(location, name)))
	if err != nil {
		return nil, err
	}

	_, err = db.Exec(`
pragma journal_mode = wal;
pragma synchronous = normal;
pragma temp_store = memory;
pragma mmap_size = 268435456;
pragma foreign_keys = on;
pragma busy_timeout = 5000;`)
	if err != nil {
		slog.Warn("pragma issue", "err", err.Error())
	}

	return db, nil
}
</code></pre>
				<small>Do lowercase SQL be a rebel!</small>

				<aside class="notes">
					PRAGMA journal_mode = wal;
					What it does: Switches the database to Write-Ahead Logging (WAL) mode instead of the default
					rollback journal mode.

					Effect:
					Transactions are written to a separate WAL file before being committed to the database, allowing
					concurrent reads and writes.

					Readers can access the database while a writer is active (unlike rollback mode, where writes
					lock
					the entire file).

					Writes are faster because they append to the WAL file rather than rewriting the main database
					file.

					Trade-off: Adds a WAL file (and potentially a -shm file for shared memory), increasing disk
					usage
					slightly. Checkpointing (merging WAL into the main DB) can lag under heavy write loads.

					PRAGMA synchronous = normal;
					What it does: Sets the synchronization level to Normal, balancing safety and speed.

					Effect:
					SQLite syncs data to disk at critical moments (e.g., after a transaction commits) but not as
					aggressively as FULL mode.

					Faster than FULL (which syncs after every write) but slower than OFF (no syncing).

					Protects against data loss in most crash scenarios, except rare OS or hardware failures.

					Trade-off: Slightly less durability than FULL (e.g., a power failure mid-transaction might
					corrupt
					the WAL), but much better performance than FULL.

					PRAGMA temp_store = memory;
					What it does: Forces SQLite to store temporary tables and indices in memory instead of on disk.

					Effect:
					Speeds up operations involving temporary data (e.g., complex JOINs, ORDER BY, or GROUP BY
					queries).

					Reduces disk I/O, which is especially helpful for large datasets or frequent temp table use.

					Trade-off: Increases memory usage. If your database workload generates lots of temp data and
					memory
					is tight, this could strain system resources.

					PRAGMA mmap_size = 268435456;
					What it does: Sets the memory-mapped I/O size to 268,435,456 bytes (256 MB).

					Effect:
					Maps the first 256 MB of the database file into memory, allowing SQLite to access it directly
					via
					memory pointers instead of traditional read/write calls.

					Boosts read performance for frequently accessed data within that 256 MB range.

					Trade-off: Uses more virtual memory, and benefits diminish if the database exceeds 256 MB (only
					the
					first chunk is mapped). Useless if the OS or hardware doesn't support memory mapping.


					PRAGMA foreign_keys = on;
					What it does: Enables foreign key constraints enforcement.

					Effect:
					Ensures referential integrity—e.g., you can’t delete a parent row if a child row references it,
					or
					insert a child row with an invalid foreign key.

					Makes the database behave more like traditional RDBMSes (e.g., PostgreSQL).

					Trade-off: Slightly slower writes due to extra checks, but it’s a safety net for data
					consistency.
					(Foreign key support is off by default in SQLite.)

					PRAGMA timeout here just specifies the timeout on the lock. You can also do it in most connection
					strings, I have repeated it here so you can see both.
				</aside>
			</section>


			<section>
				<h2>SQLite cross compiling</h2>
				<p>https://github.com/mattn/go-sqlite3</p>
				<code>GOOS=linux GOARCH=amd64 go build -ldflags="-s -w"</code>
				<p>https://modernc.org/sqlite</p>


				<aside class="notes">
					Possible to do this with the Zig toolchain these days... I am not familiar with this.


				</aside>
			</section>


			<section>
				<h2>Bloom filter</h2>
				<h2>line 159: caisson.go</h2>
				<img src="./img/bloom_example.png" style="border: none;" />

				<aside class="notes">
					bitslice signatures are built on bloom filters. So whats a bloom filter?

					In short a probablistic data structure, that you can use to test the existance of something. You add
					items, and can check if it was added. They never return false negatives, but they do occassionaly
					lie and report something being added when it was not.

					So lets look at this example,

					We have a 8 bit bloom filter, and hash two terms, golang and searchcode. Golang hashes to bit
					position 0 and searchcode to bit position 6. To add an item we do the hash, and then set the bit
					position to 1.

					If I want to check if searchcode was added, I hash it again and probe the bit position. If set to 1
					it means it was possibly added. If I want to check for the existance of awesome I could hash that
					and get the position 2 and if I probe that I can see it was never set so I know it was never added.

					The lie part comes from the hash function, where it might hash to position 0. So if I was checking
					for the existance of "java" and it hashes to bit position 0 I would assume it was added. This is a
					false positive.

					For hashing you can use any hash that returns an integer. FNV and FNVa work well for this being fast
					enough and providing enough distribution. Murmur3 is meant to be good. Note for multiple hashes you
					can salt the values to reuse hash functions.
				</aside>
			</section>

			<section>
				<h2>Frequency Concious Bloom Filter</h2>

				<aside class="notes">So hashing... While you can has terms a single time in a bloom filter, it turns out
					that you can reduce the false positive rate by having multiple hashes. If you do this dependant on
					the term input you end up with a Frequency Conscious Bloom Filter.

					The reason is that rare terms need more hashes to avoid false positives.

					To get the frequency for searchcode I just calculated the hash counts for every bit of code I found
					find and removed all the common ones. I then use a weight to determine how many hashes each term
					needs.

					Its left as an exercise to yourselves to implement this, as I just hardcoded it to 3 hashes here.

					BTW this is one of the things you need to do at a large enough scale to get the performence you need
					and is something I put into searchcode.</aside>
			</section>

			<section>
				<h2>Advantages</h2>
				<ul>
					<li>Compressed</li>
					<li>Simple</li>
				</ul>
				<aside class="notes">Bloom filters have a lot going for them. They are compressed by nature, getting
					down to 9 bits per term added if you do them right. They are also really simple to implement. Note
					there are other filters like this, such as ribbon or xor, but as far as I know you cannot use them
					in the way I do here.</aside>
			</section>

			<section>
				<section>
					<h2>Bloom filter search</h2>
					<img src="./img/bloomfilter.png" style="border: none;" />
					<aside class="notes">
						So how to search over out bloom filter index? This represents 4 documents in our index. All
						indexed using an 8 bit bloom filter. We took in documents, turned them into trigrams, got the
						hash positions and set the bit.
						So now we search...
					</aside>
				</section>
				<section>
					<img src="./img/bloomfilter_1.png" style="border: none;" />
					<aside class="notes">
						Given our input of "golang" and "searchcode" we want to probe bit positions at 0 and 6.
					</aside>
				</section>
				<section>
					<img src="./img/bloomfilter_2.png" style="border: none;" />
				</section>
				<section>
					<img src="./img/bloomfilter_3.png" style="border: none;" />
				</section>
				<section>
					<img src="./img/bloomfilter_4.png" style="border: none;" />
				</section>
				<section>
					<img src="./img/bloomfilter_match.png" style="border: none;" />
				</section>
			</section>

			<section>
				<h2>Problems</h2>
				<aside class="notes">
					So a few problems with this approach.

					Problem is that each "bit" in this uses 1 byte under the hood, assuming we use a boolean to indicate
					the bit. A 8x overhead is unacceptable for most...

					Another problem is that is that its slow... This comes down to how fetching bits out of memory using
					the CPU works. The slow part is not the & logic you use, but memory walking.

					When you probe a single bit on any system you actually pull back 512 bits from RAM. A 512x overhead
					just to test a single bit! As a result on average you end up walking ALL the memory for your filter.

					If you have a index thats 100 GB in size, using a modern CPU its going to take ~2 seconds to walk
					all that memory, and thats irespective of how many cores you have. You become memory bound.

					This is one one of the reasons this as an approach fell out of favor in the 70's.
				</aside>
			</section>

			<section>
				<section>
					<h2>Fixes</h2>
					<img src="./img/rotated_bloomfilter.png" height="500px" style="border: none;" />
					<aside class="notes">
						However in the 80's a smart person called Roberts noticed you could rotate the filter.

						So we do that by turning the rows into columns. So each row used to represent a document, but
						now each column does. Right to left.

						With this done we only need to inspect the rows containing the bit positions of the query. So in
						this case 2 rows which is half the memory access.

						We can then using out examples just row query bit positions 0 and 6 and then logically & them
						together. If they arent 0 then we have a positional match.

					</aside>
				</section>
				<section>
					<img src="./img/rotated_bloomfilter_1.png" style="border: none;" />
				</section>
				<section>
					<img src="./img/rotated_bloomfilter_2.png" style="border: none;" />
					<aside class="notes">
						Logically we & together 1010 and 1000 and we get that document 4 on the left is portentially a
						match
						This reduces the amount of RAM we need to access by factor of about 200 for larger bloom
						filters.</aside>
				</section>
			</section>



			<section>
				<h2>Add</h2>
				<h2>line 187: caisson.go</h2>
				```<code style="font-size: 14px; line-height: 1em;">var bloomFilter []uint64

func Add(item []bool) error {
	if len(item) != BloomSize {
		return errors.New(fmt.Sprintf("expected to match size %d", BloomSize))
	}

	if currentBlockDocumentCount == 0 || currentBlockDocumentCount == DocumentsPerBlock {
		bloomFilter = append(bloomFilter, make([]uint64, BloomSize)...)
		currentBlockDocumentCount = 0

		if currentDocumentCount != 0 {
			currentBlockStartDocumentCount += BloomSize
		}
	}

	for i, bit := range item {
		if bit {
			bloomFilter[currentBlockStartDocumentCount+i] |= 1 << currentBlockDocumentCount
		}
	}

	currentBlockDocumentCount++
	currentDocumentCount++

	return nil
}
</code>```
				<aside class="notes">So given that lets build out bloom filter by adding documents.

					What this does is takes in boolean slice, checks if its the right size, then checks if we need to
					add a new
					block IE another batch of 64 documents, and then loops over the input setting the correct bits in
					the correct position.</aside>
			</section>



			<section>
				<h2>Optimise</h2>
				<h2>line 187: caisson.go</h2>
				```<code style="font-size: 14px; line-height: 1em;">1001010000001111000001111001101110100011111111111111111111111101
0110111101101010111111111001001101110000000000010000100000000000
0000000000001000000000000000000000000000000000000000000000000000
0000000000001001000010110000001000100011111100000000000000000000
1000011100000000000010000001001000100000000000000000000000000000
0111011100000100000011110001000011000000000000000000000000000000
0001000000001000000010000001000100000000000000000000000000000000
0000001000001010101000010000001000001000000000000001000000000000
0100000000001011000000000100001000111100000000000000000000000000
0000001000011011001000001010100100100001111100000001010101011110
0001011100000100000001000101101110000010000010001010101010100011
0000101000000001000001000001000001011000000000000000000000000000
1111111111111111111111011011111101101011111111111111111111111111
0000000000001000001000010000000000110000001000000001100000001000
0000000000001000001010010000000010100010000111111110101010100001
0000000000001000000000010000011001100011111100000000000000000000
</code>```
				<aside class="notes">This is done so as to not waste memory. In the code its done by packing 64
					documents into a bloom filter block or bucket.

					So if a bloom filter had 16 bits, we keep 16 uint64's in a slice.

					It would look like what you see, and you can print it out if you modify the code.
					This ensures we are optimally using the space. Because we pack 64 documents into each bucket we end
					up using a single bit per location in the bloom filter. No 8x waste!

					It also becomes very fast to walk this because its a simple for loop. And we all know for loops go
					brrrr.
				</aside>
			</section>

			<section>
				<h2>searchcode...</h2>
				```<code style="font-size: 14px; line-height: 1em;">
┌──────────────────┐   ┌──────────────────┐   ┌──────────────────┐
│     caisson      ├─┬▶│  shard 512 bits  ├┬─▶│     bucket-1     │
└──────────────────┘ │ └──────────────────┘│  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     ├─▶│     bucket-2     │
                     │                     │  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     └─▶│     bucket-3     │
                     │                        └──────────────────┘
                     │                                            
                     │                                            
                     │ ┌──────────────────┐   ┌──────────────────┐
                     └▶│  shard 1024 bits ├┬─▶│     bucket-1     │
                       └──────────────────┘│  └──────────────────┘
                                           │                      
                                           │  ┌──────────────────┐
                                           ├─▶│     bucket-2     │
                                           │  └──────────────────┘
                                           │                      
                                           │  ┌──────────────────┐
                                           └─▶│     bucket-3     │
                                              └──────────────────┘
</code>```
				<aside class="notes">In searchcode its a little more in depth because it actually changes the size of
					the bloom filters based on the size of the document its indexing.

					What happens is when a document is indexed, it breaks it into unique trigrams, and then finds a
					bloom filter where it will be stored with a target bit density. If the document has a small amount
					of trigrams it ends up in a smaller bloom filter of say 256 bits, and if larger it goes into a
					larger one up to 4096.

					When the full 64 documents have been added to a bucket then in the case of a 256 bit bloom filter
					another 256 uint64's are appended on the end.

					Where shards represent a different bloom filter size, say 512 of 2048 bits, and buckets exist as a
					single uint64 slice in a shard. They are split out logiclly here to help understanding.
				</aside>
			</section>


			<section>
				<h2>Searching</h2>
				<h2>line 20: caisson.go</h2>
				```<code style="font-size: 14px; line-height: 1em;">func Search(queryBits []uint64) []uint32 {
	var results []uint32
	var res uint64

	if len(queryBits) == 0 {
		return results
	}

	for i := 0; i < len(bloomFilter); i += BloomSize {
		res = bloomFilter[queryBits[0]+uint64(i)]

		for j := 1; j < len(queryBits); j++ {
			res = res & bloomFilter[queryBits[j]+uint64(i)]

			if res == 0 {
				break
			}
		}

		if res != 0 {
			for j := 0; j < DocumentsPerBlock; j++ {
				if res&(1<<j) > 0 {
					results = append(results, uint32(DocumentsPerBlock*(i/BloomSize)+j))
				}
			}
		}

	}

	return results
}
</code>```
				<aside class="notes">With the index done we can now search.

					The core search algorithm is as follows.

					I find this algorithm beautifully simple. We take in query positions for the search, so in the case
					of searching for "searchcode" we turn that into trigrams
					then hash them using the same hash functions to get 6+ uint64's from 0 to whatever the filter is
					configured to be in a slice.

					Then, walk over each logical block or bucket, which is as many uint64's as exist in the bloom
					filter, and then logically & that against the previous one.
					If its 0 bail out, otherwise if we have finished record the documentid based on what its position in
					the index is.


					Whats really cool about this is that we jump potentially all of the bytes in a block if we hit that
					res == 0 condition quickly, avoiding us walking any memory at all! This is the state we want
					to hit as often as possible.

					Results when returned gives ids, which we can then use the idToFile to find the true id for this
					document.

					Once we have these id its a matter of reaching out to our primary data store, pulling back the
					documents and processing from there.
				</aside>
			</section>


			<section>
				<h2>Size</h2>
				```<code style="font-size: 14px; line-height: 1em;">$ scc --no-cocomo caisson.go
───────────────────────────────────────────────────────────────────────────────
Language                 Files     Lines   Blanks  Comments     Code Complexity
───────────────────────────────────────────────────────────────────────────────
Go                           1       235       41        52      142         36
───────────────────────────────────────────────────────────────────────────────
Total                        1       235       41        52      142         36
───────────────────────────────────────────────────────────────────────────────
Processed 6746 bytes, 0.007 megabytes (SI)
───────────────────────────────────────────────────────────────────────────────
</code>```
				<aside class="notes">As you can see its a short bit of code. Only about 150 lines. I really encourage
					you to have a look and play with it.</aside>
			</section>


			<section>
				<h2>Demo</h2>

				<aside class="notes">This is meant to be interactive... I hope you have been following the code...

					So lets try it on itself...

					And assuming nobody has crashed searchcode since I started talking here it is.

					So you can search for all sorts of things. Where searchcode is a bit different is that while it can
					do exact matches its more useful looking for related things.

					A good example being how to use gson with mongodb in java.

					Or looking for random things. For example I know Chewys gorgonia has something to do with newtape .
				</aside>
			</section>



			<section>
				<h2>Thank You!</h2>
				<small>ChatGPT:
					The main problem with using a bitfunnel bit slice signature approach for code search is that it
					would be very inefficient. This is because bitfunnel bit slice signatures are designed for searching
					short, text-based documents. Code, on the other hand, is much longer and more complex than
					text-based documents. This means that bitfunnel bit slice signatures would be very large and
					inefficient for storing code.

					In addition, bitfunnel bit slice signatures are not very accurate. This is because they are
					probabilistic data structures. This means that there is a small chance that a bitfunnel bit slice
					signature will return a false positive. This is not a problem for text-based documents, but it can
					be a problem for code. This is because code is often very repetitive. This means that there is a
					high chance that a bitfunnel bit slice signature will return a false positive when searching for a
					particular trigram.

					For these reasons, I would not recommend using a bitfunnel bit slice signature approach for code
					search. Instead, I would recommend using an inverted index.

				</small>
				<p>Presentation located at <a
						href="https://boyter.org/static/golang-syd-25th-may/">https://boyter.org/static/golang-syd-25th-may/</a>
					or just go to boyter.org and I will link it up tomorrow.</p>
				<aside class="notes">
					Of course... probably nobody using searchcode probably cares that its running on a unique bloom
					filter trigram backed index with
					ideas borrowed from bing. But I know... and now you do too.

					Now this is meant to be interactive, so ill bring the code up and we can talk about whatever you
					like given time and get some questions out of the way.
				</aside>
			</section>

		</div>
	</div>

	<script src="lib/js/head.min.js"></script>
	<script src="js/reveal.js"></script>

	<script>
		// More info about config & dependencies:
		// - https://github.com/hakimel/reveal.js#configuration
		// - https://github.com/hakimel/reveal.js#dependencies
		Reveal.initialize({
			dependencies: [
				{ src: 'plugin/markdown/marked.js' },
				{ src: 'plugin/markdown/markdown.js' },
				{ src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } }
			]
		});
	</script>
</body>

</html>