<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>GopherConSyd 2023</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Bloom Filters: Building a Cutting Edge Go Search Engine to Explore the World's Source Code</h1>
					<!--<a href="https://github.com/boyter/indexer">https://github.com/boyter/indexer</a>
					<p>Go get a copy of the above!</p>-->
					<aside class="notes">So as part of the interactive theme, id suggest everyone go and get a copy of the above. Or just go hammer searchcode.com with stuff.</aside>
				</section>

				<section>
					<h2>Who are you?</h2>
					<p>
					"Officially" technical lead/principle at Kablamo but a "code monkey" at heart.</p>
					<p>I blog <a href="https://boyter.org/">boyter.org</a> I free software <a href="https://github/boyter/">github/boyter/</a> I run <a href="https://searchcode.com/">searchcode.com</a> also on the twitter <a href="https://twitter.com/boyter">@boyter</a> activitypub <a href="https://honk.boyter.org/boyter">@boyter@honk.boyter.org</a></p>
					<aside class="notes">Not going to bore you too much with who I am because you don't care.
					</aside>
				</section>


				<section>
					<h2>PHP -> Python -> Java -> Go</h2>
					<img src="./img/sphinx_manticore.png" style="border: none;" />
					<img src="./img/searchcode.gif" height="500px;" style="border: none;" />
					<aside class="notes">
So I run searchcode.com which as the un-imaginative name would suggest searches over source code. 
I have been doing this for the last 10 years modifying and rewriting it from PHP to Python to 
Java and finally to Go.

Searchcode itself indexes about 75 billion lines of code across 40 million projects pulled from 
github, gitlab, bitbucket, codeberg, sr.ht and such.

Its sort of a serious side project, where I get to have a wonderful time working on neat algorithms.
It gets enough traffic to make it interesting.

Which is nice compared to the usual code golf I get to deal with. Im sure if I fiddle with this a bit more
I can reduce to code count by a third!

The whole time that has happened one thing has been constant, which was the use of the 
index engine, which was provided using Sphinx Search and then a forked version called Manticore.

This made me feel like a bit of a fraud, how can I claim to be a search guy without 
using my own index. So after the early in 2020, I decided I would build my own index.
					</aside>
				</section>

				<section>
					<h2>Considerations</h2>
					<ul>
						<li>Free service
							<ul>
								<li>Put everything in RAM</li>
								<li>Downtime not a huge issue</li>
								<li>Single server</li>
								<li>Single binary, no daemons!</li>
							</ul>
						</li>
						<li>Boolean queries</li>
 						<li>Single developer</li>
						<li>This is how I built an index... not necessarily how you should build one!</li>
					</ul>
					<aside class="notes">
					Design Considerations
Now we need to consider the goals of searchcode.com
its free... this influences the design, because I don't need to worry about pesky cusotmers, 
if the service goes down
put it all in ram! cos ram is cheap right?
downtime is not a huge problem
single server!
Turns out most people just type terms and expect results, VERY few people actually do boolean queries
Needs to be understandable by me... this is where Go is really useful.
I like the language but I die a little for all the error handling conditions I deal with
Then I realise I finished whatever I was doing really quickly and get over it
I don't think I would have gotten as far as I did without using Go
					</aside>
				</section>

				<section>
					<section>
							<h2>Searching: Tokenisation</h2>
							<p>Mapping / Stemming</p>
	<pre><code style="font-size: 18px; line-height: 1em;">searchcode -> searchcode
likes      -> like
liked      -> like
likely     -> like
	</code></pre>
	<p>Does not work for code!</p>
	<pre><code style="font-size: 18px; line-height: 1em;">for(i=0;i++;i&lt;100)</pre></code>
							<aside class="notes">
	So code search is in some ways easier than text, because you don't need to try to understand language in the way that you do when dealing with english, japanese or russian. Splitting on chinese or japanese words for example is painful.

	You can solve this problem in code using whats known as trigrams, where you break the text apart into characters of 3 and index those. You can actually use any number you want for ngrams, but trigrams work best when indexing source code.

	One catch with this is that you get false positives, some inputs generate the same ngrams despite being different. You also have terms with low cardinality such as repeated works in a line. So the letter p 100 times is no more useful than 3 of them.

	Another issue is that you get more things to index bloating your posting list... We will get into what posting lists are shortly? Well lets have a look at how to build an index

	But have a look here, were one term searchcode is turned into 8 things we need to index.
							</aside>
					</section>
					<section>
						<h2>Searching code: Tokenisation</h2>
						<p>Trigrams</p>
<pre><code style="font-size: 18px; line-height: 1em;">searchcode ->	sea
		ear
		arc
		rch
		chc
		hco
		cod
		ode
</code></pre>
						<aside class="notes">
So code search is in some ways easier than text, because you don't need to try to understand language in the way that you do when dealing with english, japanese or russian. Splitting on chinese or japanese words for example is painful.

You can solve this problem in code using whats known as trigrams, where you break the text apart into characters of 3 and index those. You can actually use any number you want for ngrams, but trigrams work best when indexing source code.

One catch with this is that you get false positives, some inputs generate the same ngrams despite being different. You also have terms with low cardinality such as repeated works in a line. So the letter p 100 times is no more useful than 3 of them.

Another issue is that you get more things to index bloating your posting list... We will get into what posting lists are shortly? Well lets have a look at how to build an index

But have a look here, were one term searchcode is turned into 8 things we need to index.
						</aside>
					</section>
					<section>
						<h2>Problems</h2>
						<p>Creates long posting lists</p>
						<p>Introduces false positives</p>
<pre><code style="font-size: 18px; line-height: 1em;">searchcode ->	sea
		ear
		arc
		rch
		chc
		hco
		cod
		ode

vs

searchcode -> searchcode
</code></pre>
						<aside class="notes">
If we tokenise by trigrams we get a great dela more tokens we need to index. In our example from before
searchcode turns into 8 things we need to add to our index, vs a single thing we would need if we treated
it as plain space delimited text.
						</aside>
					</section>
					<section>
						<h2>Trigram Generation<h2>
<pre><code style="font-size: 14px; line-height: 1em;">func Trigrams(text string) []string {
	var runes = []rune(text)

	if len(runes) <= 2 {
		return []string{}
	}

	ngrams := make([]string, len(runes)-2)

	for i := 0; i < len(runes); i++ {
		if i+3 < len(runes)+1 {
			ngram := runes[i : i+3]
			ngrams[i] = string(ngram)
		}
	}

	return ngrams
}
</code></pre>
					<aside class="notes">
When you look at how this is called you will notice logic to split in spaces first and 
then index things larger than 3. This avoids indexing spaces which reduces the 
size of the bloom filter.

Interesting fact, this is by far the single biggest bottleneck in searchcode when indexing.
If someone wants to profile and improve performance on it I would really appreciate it. 
It dominiates the indexing profile by a huge amount.</aside>
					</section>
					<section>
					<img src="./img/nerdsniped.png" style="border: none;" />
					<aside class="notes">
Consider yourself nerd sniped
					</aside>
				</section>

				</section>

				

				<section>
					<section>
						<h2>What is an index?</h2>
						<p>Structured list. Keys point at data so searches are faster.</p>
						<p>Given a term, return id's which contain it.</p>
					</section>
					<section>
						<h2>Textbook 101 index</h2>

<pre><code style="font-size: 14px; line-height: 1em;">package main

func main() {
	// non-positional index
	index := map[string][]int{} 
	index["gopher"] = append(index["gopher"], 1337)

	// positional index
	type pos struct {
		id  int   // unique document id
		loc []int // store document positions in posting list
	}
	posIndex := map[string][]pos{} 
	posIndex["gopher"] = append(posIndex["gopher"], pos{1337, []int{1, 2, 3, 99}})
}
</code></pre>

						<aside class="notes">
So given our trigram terms we now need to index them. There are a few ways to do this. Lets walk through a few.

A posting list is the slice of struct or int64 containing the document's that contain that term.

So "set" is found inside documents 1,77 and 345

A positional index is one that stores where the term was found in the document. 

So "set" as position 5 and 56 inside document 77

This is really useful for phrase searches and ranking.
In theory you can then use the index to reconstruct the document entirely. One catch with this is that your index becomes larger than the thing you are indexing.

Done simply these are a bit of code you can had over to your cousin or most junior developer.

Skip lists are something you end up needing to implement because when searching multiple terms you look for 
the intersection of multiple posting lists and it speeds things up and something you need to add to scale this approach.

They are an interesting data structure worth looking up on wikipedia. When you start adding compression using ellias phano to reduce the size they quickly become complex, and it becomes easy to tank your performance.
						</aside>
					</section>
					<section>
						<h2>Problem: Intersect two lists</h2>
						<img src="./img/assvogel.gif" height="500px;" style="border: none;" />
						<ul>
							<li>Trigrams create LONG posting lists</li>
							<li>Need to implement skip lists AND compression at scale</li>
						</ul>

						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>For those wondering...</h2>
						<img src="./img/vulture.jpg" style="border: none;" />
						<aside class="notes">
						Assvogel is an obsolete Afrikaans word for a South African vulture 
						</aside>
					</section>
					<section>
						<h2>Problem 2</h2>
						<h3>Compression</h3>
						<pre><code style="font-size: 14px; line-height: 1em;">index := map[string][]int{} // this should be compressible right?</code></pre>
						<img src="./img/elias_fano.png" style="border: none;" />
						<aside class="notes">
Elias Fano compression is a technique used to compress a sorted list of integers, primarily in the context 
of information retrieval and data compression. It was designed to take advantage of the properties 
of sorted lists, where the integers are typically increasing.
						</aside>
					</section>
					<section>
						<h2>Complexity</h2>
						<pre><code style="font-size: 16px; line-height: 1em;">index := map[string][]int{} // non-positional index
</code></pre>
<p>vs</p>
						<img src="./img/complex.png" style="border: none;" />
						<aside class="notes">
This is clearly a lot more complex than what we started with. Certainly more than I am willing to deal with.

Trust me you don't want me writing algorithms like this.
						</aside>
					</section>
					<section>
						<h2>My attempt</h2>
						<p>Two turkeys duct taped together does not make an eagle.</p>
						<img src="./img/turkeys.jpg"  height="500px;" style="border: none;" />
						<aside class="notes">
This is clearly a lot more complex than what we started with. Certainly more than I am willing to deal with.

Trust me you don't want me writing algorithms like this.
						</aside>
					</section>
					
				</section>

				<!--<section>
					<h2>Trie</h2>
					<p>Typesense uses this, its also written in C++</p>
<img src="./img/trie.png" height="100px" style="border: none;" />
					<ul>
						<li>Big problem is not friendly to GC due to the use of pointers</li>
						<li>Still need skip lists + compression on the posting lists</li>
 						<li>Makes wildcard queries easier</li>
					</ul>

					<aside class="notes">
I tried this, and the GC non friendly problem caused it to have massive delays while walking the pointers. 
I think it was seconds in GC when I tried it which was unacceptable.

I could have possibly done off heap tricks but I wanted to stick to normal Go because I am a mortal programmer.

So what about bitslice signatures?
					</aside>
				</section>-->

				<section>
					<section>
						<h2>How about bloom filters?</h2>
						<p>Whats a bloom filter?</p>
					</section>
					<section>
						<h2>Bloom filter: Empty</h2>
						<p>16 boolean's in an array</p>
	<img src="./img/BloomFilter1.png" style="border: none;" />
						<aside class="notes">
Bitslice signatures are built on bloom filters. So whats a bloom filter?

In short a probablistic data structure, that you can use to test the existance of something. 
You add items, and can check if it was added. They never return false negatives, but they do occassionaly lie and report something being added when it was not.

So lets look at this example,

We have a 8 bit bloom filter, and hash two terms, golang and searchcode. Golang hashes to bit position 0 and 
searchcode to bit position 6. To add an item we do the hash, and then set the bit position to 1.

If I want to check if searchcode was added, I hash it again and probe the bit position. 
If set to 1 it means it was possibly added. If I want to check for the existance of awesome I could 
hash that and get the position 2 and if I probe that I can see it was never set so I know it was never added.

The lie part comes from the hash function, where it might hash to position 0. So if I was checking for 
the existance of "java" and it hashes to bit position 0 I would assume it was added. This is a false positive.

For hashing you can use any hash that returns an integer. FNV and FNVa work well for this being fast enough and providing enough distribution. Murmur3 is meant to be good. Note for multiple hashes you can salt the values to reuse hash functions.

						</aside>
					</section>
					<section>
						<h2>Bloom filter: Add</h2>
						<p>Hash the term 3 times and set the bits</p>
	<img src="./img/BloomFilter2.png" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Add second</h2>
						<p>3 more bits set</p>
	<img src="./img/BloomFilter3.png" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Add overlapping bits</h2>
						<p>"big" and "dog" share 2 bits</p>
	<img src="./img/BloomFilter4.png" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Hit</h2>
						<p>hash "big" and check bits</p>
	<img src="./img/BloomFilter5.png" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Miss</h2>
						<p>one bit position is 0 so miss</p>
	<img src="./img/BloomFilter7.png" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Bloom filter: False Positive</h2>
						<p>big and yellow supplied bits</p>
	<img src="./img/BloomFilter6.png" style="border: none;" />
						<aside class="notes">
While bloom filters do introduce false positives, you have to deal with them anyway since we are using trigrams.
So this is not a deal breaker. Also ranking the documents can help with this.
						</aside>
					</section>

					<section>
						<h2>Go Bloom Filter</h2>

<pre><code style="font-size: 14px; line-height: 1em;">package main

import (
	"fmt"
	"hash/fnv"
)

func main() {
	bloom := make([]bool, 16)          // 16 bit bloom filter
	hash := func(term string) uint64 { // single hash function for bloom filter
		hsh := fnv.New64()
		_, _ = hsh.Write([]byte(term))
		return hsh.Sum64() % uint64(len(bloom))
	}

	bloom[hash("gopher")] = true // add to the filter
	bloom[hash("sydney")] = true

	for _, i := range bloom { // print out the filter
		if i == true {
			fmt.Print("1")
		} else {
			fmt.Print("0")
		}
	}

	if bloom[hash("sydney")] == true { fmt.Print("\nprobably added") }
	if bloom[hash("house")] == false { fmt.Print("\nwas not added") }
	if bloom[hash("boyter")] == true { fmt.Print("\nfalse positive! was never added!") }
}
</code></pre>

<pre><code style="font-size: 14px; line-height: 1em;">$ go run main.go 
0010000001000000
probably added
was not added
false positive! was never added!
</code></pre>

						<aside class="notes">
						</aside>
					</section>

					<section>
						<h2>Bloom filter: search</h2>
					
						<p>Check bit positions 1 and 7. Document 4 matches.</p>
						<pre><code style="font-size: 14px; line-height: 1em;">for each bloomfilter
	for each bit
		check if bit location in filter is set
	if all matching bits are set
		record possible match</code></pre>

						<img src="./img/bloom_naieve_search.gif" height="500px" style="border: none;" />

						<aside class="notes">
	So how to search over out bloom filter index? This represents 4 documents in our index. All indexed using an 8 bit bloom filter. We took in documents, turned them into trigrams, got the hash positions and set the bit.
	So now we search...
						</aside>
					</section>
				</section>


				<!--<section>
						<h2>Frequency Concious Bloom Filter</h2>

					<aside class="notes">So hashing... While you can has terms a single time in a bloom filter, it turns out that you can reduce the false positive rate by having multiple hashes. If you do this dependant on the term input you end up with a Frequency Conscious Bloom Filter.

The reason is that rare terms need more hashes to avoid false positives.

To get the frequency for searchcode I just calculated the hash counts for every bit of code I found find and removed all the common ones. I then use a weight to determine how many hashes each term needs.

Its left as an exercise to yourselves to implement this, as I just hardcoded it to 3 hashes here.

BTW this is one of the things you need to do at a large enough scale to get the performence you need and is something I put into searchcode.</aside>
				</section>-->

				<section>
					<section>
						<h2>Advantages</h2>
						<ul>
							<li>Compressed. Only using several bits per term</li>
							<li>Very simple!!!!
								<ul>
								<li>Adding</li>
								<li>Editing</li>
								<li>Searching</li>
								<li>Extensible</li>
								</ul>
							</li>
						</ul>
						<aside class="notes">
Bloom filters have a lot going for them. They are compressed by nature, getting down to 9 bits per term 
added if you do them right. They are also really simple to implement. 
Note there are other filters like this, such as ribbon or xor, but as far as I know you cannot 
use them in the way I do here.</aside>
					</section>
					<section>
						<h2>Problems</h2>
						<p>No free lunch...</p>
<pre><code style="font-size: 14px; line-height: 1em;">package main
			
import (
	"fmt"
	"runtime"
)

func main() {
	memUsage := func() string {
		var m runtime.MemStats
		runtime.ReadMemStats(&m)
		return fmt.Sprintf("%v MB", m.Alloc/1024/1024)
	}

	fmt.Println(memUsage())
	bigBloom := make([]bool, 100_000_000) // represents lots of bloom filters in memory
	fmt.Println(memUsage())
	_ = len(bigBloom)
}

$ go run main.go
0 MB
95 MB</code></pre>
						<aside class="notes">
So there a few problems with this approach.

Firstly.

How much memory does 100 million bools take up? Almost 100 MB which if you calculate is about 8x what you expect.

Problem is that each "bit" in this uses 1 byte under the hood since they are all addressable.
Note this isnt a problem with Go it occurs in most languages.
						</aside>
					</section>
					<section>
						<h2>Problem 2</h2>
						<p>Generic RAM stick</p>
						<img src="./img/ram.jpg" height="500px" style="border: none;" />
						<aside class="notes">
Another problem is that is that its slow... This comes down to how fetching bits out of 
memory using the CPU works.

When you probe a single bit on most modern sysems you actually pull back 512 bits from RAM. This is because usually a 
full cache line is read, which is 512 bits or 64 bytes. So a 512x overhead just to test a single bit! 

As a result on average you end up walking ALL the memory for your filter, depending on which bits your proble.

This is one one of the reasons this as an approach fell out of favor in the 70's, because in practice
you do end up walking all the addressable memory.
						</aside>
					</section>
					<section>
						<h2>Problem 2</h2>
						<img src="./img/2048_bloom.png" height="500px" style="border: none;" />
						<aside class="notes">
So for bloom filters this is a huge problem, because if you have a proper hash function you get a 
distribution that means you end up walking all the memory... which sounds fine.

Till you realise modern CPU's arent as fast as you would think for memory,

Theoretical bandwidth for CPU's is something like 100 GB/s

In theory theory and practice are the same, in practice they are not, you don't see

So if you had an index taking 100 GB in memory your theoretical request per second is 1

In reality is much lower because of overheads, where you are more likely to get less than 50 GB/s

So if you have say 2048 bits in your bloom filter, and you probe 6 bits or so 3 trigrams you are likely to 
pull all of the 2048 bits across the CPU						</aside>
					</section>
					<section>
						<h2>Problem 2</h2>
						<img src="./img/2048_bloom_2.png" height="500px" style="border: none;" />
						<aside class="notes">
So for bloom filters this is a huge problem, because if you have a proper hash function you get a 
distribution that means you end up walking all the memory... which sounds fine.

Till you realise modern CPU's arent as fast as you would think for memory,

Theoretical bandwidth for CPU's is something like 100 GB/s

In theory theory and practice are the same, in practice they are not, you don't see

So if you had an index taking 100 GB in memory your theoretical request per second is 1

In reality is much lower because of overheads, where you are more likely to get less than 50 GB/s

So if you have say 2048 bits in your bloom filter, and you probe 6 bits or so 3 trigrams you are likely to 
pull all of the 2048 bits across the CPU						</aside>
					</section>
					<section>
						<h2>Problem 3</h2>
						<img src="./img/2048_bloom_3.png" height="500px" style="border: none;" />
						<aside class="notes">
So for bloom filters this is a huge problem, because if you have a proper hash function you get a 
distribution that means you end up walking all the memory... which sounds fine.

Till you realise modern CPU's arent as fast as you would think for memory,

Theoretical bandwidth for CPU's is something like 100 GB/s

In theory theory and practice are the same, in practice they are not, you don't see

So if you had an index taking 100 GB in memory your theoretical request per second is 1

In reality is much lower because of overheads, where you are more likely to get less than 50 GB/s

So if you have say 2048 bits in your bloom filter, and you probe 6 bits or so 3 trigrams you are likely to 
pull all of the 2048 bits across the CPU						</aside>
					</section>
				</section>

				
				

				<section>
					<section>
						<h2>Bitfunnel</h2>
						<p>Good enough for Dan Luu? Good enough for you.</p>
						<img src="./img/bitfunnel.png" style="border: none;" />
						<aside class="notes">
Bing paper - BitFunnel: Revisiting Signatures for Search
Dan Luu is a co-author. Anything he writes I pay attention to.
Good enough for Dan Luu, Good enough for you.

Supposedly at this point it powers every query thats comes into Bing.

It did win best paper at SIGIR, which is probably the most prestigious IR conferences.
						</aside>
					</section>
					<section>
							<h2>Fixes</h2>
							<p>Rotate the filter. Documents now on columns not rows.</p>
							<img src="./img/rotate.gif" height="500px" style="border: none;" />
							<aside class="notes">
However in the 80's a smart person called Roberts noticed you could rotate the filter, 
assuming each filter has the same exact size, IE the same number of bits.

So we do that by turning the rows into columns. So each row used to represent a document, but now each column does. Right to left.

With this done we only need to inspect the rows containing the bit positions of the query. 
So in this case 2 rows which is half the memory access.

We can then using out examples just row query bit positions 0 and 6 and then logically & them together. If they arent 0 then we have a positional match.

		</aside>
					</section>
					<section>
						<p>Rotated filter (documents are columnns now)</p>
						<img src="./img/rotate1.png" height="500px" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<p>Fetch row 1 and 7 same as previous example</p>
						<img src="./img/rotate3.png" height="500px" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<p>Logically & all rows</p>
						<img src="./img/rotate4.png" height="500px" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<p>Pos 1 is true, so document 4 matches</p>
						<img src="./img/rotate5.png" height="500px" style="border: none;" />
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Results?</h2>
						<p>This reduces the amount of RAM we need to access by a huge factor for larger bloom filters.</p>
						<aside class="notes"></aside>
					</section>

					<section>
						<h2>Pack the bits with bit set</h2>
						<p>Use int64's to hold the filters in columns, and flip bits starting right to left.</p>
<pre><code style="font-size: 14px; line-height: 1em;">var bloomFilter []uint64
var bloomSize = 16
var currentBlockDocumentCount = 0
var currentBlockStartDocumentCount = 0

func Add(item []bool) error {
	if currentBlockDocumentCount == 0 || currentBlockDocumentCount == 64 {
		bloomFilter = append(bloomFilter, make([]uint64, bloomSize)...)
		currentBlockDocumentCount = 0
		currentBlockStartDocumentCount += bloomSize
	}

	for i, bit := range item {
		if bit {
			bloomFilter[currentBlockStartDocumentCount+i] |= 1 << currentBlockDocumentCount
		}
	}

	currentBlockDocumentCount++
	currentDocumentCount++

	return nil
}
</code></pre>
					<aside class="notes">So given that lets build out bloom filter by adding documents.
					
What this does is takes in boolean slice, then checks if we need to add a new 
block IE another batch of 64 documents, and then loops over the input setting the correct bits in the correct position.</aside>
					</section>




					<section>
						<h2>Result</h2>
						<p>16 bit bloom filter, with 32 documents added. Less wasted space.</p>
<pre><code style="font-size: 14px; line-height: 1em;">bloomFilter := make([]int64, 16) 
</code></pre>
<pre><code style="font-size: 14px; line-height: 1em;">0000000000000000000000000000000010100011111111111111111111111101
0000000000000000000000000000000001110000000000010000100000000000
0000000000000000000000000000000000000000000000000000000000000000
0000000000000000000000000000000000100011111100000000000000000000
0000000000000000000000000000000000100000000000000000000000000000
0000000000000000000000000000000011000000000000000000000000000000
0000000000000000000000000000000000000000000000000000000000000000
0000000000000000000000000000000000001000000000000001000000000000
0000000000000000000000000000000000111100000000000000000000000000
0000000000000000000000000000000000100001111100000001010101011110
0000000000000000000000000000000010000010000010001010101010100011
0000000000000000000000000000000001011000000000000000000000000000
0000000000000000000000000000000001101011111111111111111111111111
0000000000000000000000000000000000110000001000000001100000001000
0000000000000000000000000000000010100010000111111110101010100001
0000000000000000000000000000000001100011111100000000000000000000
</code></pre>
						<aside class="notes">
						
	This is done so as to not waste memory. In the code its done by packing 64 documents into a bloom filter block or bucket. 

	So if a bloom filter had 16 bits, we keep 16 int64's in a slice.

	It would look like what you see, and you can print it out if you modify the code.
	This ensures we are optimally using the space. Because we pack 64 documents into each 
	bucket we end up using a single bit per location in the bloom filter. No 8x waste!

	It also becomes very fast to walk this because its a simple for loop. And we all know for loops go brrrr.
	</aside>
					</section>
			
					<section>
						<h2>Sharding</h2>
						<p>Shard based on the length of the document we want to index.</p>
<pre><code style="font-size: 14px; line-height: 1em;">0000000100000000 // underfilled bloom filter
1011111111111110 // overfilled bloom filter</code></pre>
						<p>Result? Less wasted space. Squeeze every bit.</p>
<pre><code style="font-size: 14px; line-height: 1em;">
┌──────────────────┐   ┌──────────────────┐   ┌──────────────────┐
│     caisson      ├─┬▶│  shard 512 bits  ├┬─▶│ bucket-1 64 docs │
└──────────────────┘ │ └──────────────────┘│  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     ├─▶│ bucket-2 64 docs │
                     │                     │  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     └─▶│ bucket-3 64 docs │
                     │                        └──────────────────┘
                     │                                            
                     │                                            
                     │ ┌──────────────────┐   ┌──────────────────┐
                     └▶│  shard 1024 bits ├┬─▶│ bucket-1 64 docs │
                       └──────────────────┘│  └──────────────────┘
                                           │                      
                                           │  ┌──────────────────┐
                                           └─▶│ bucket-2 64 docs │
                                              └──────────────────┘
</code></pre>
						<aside class="notes">
	In searchcode its a little more in depth because it actually changes the size of the bloom filters 
	based on the size of the document its indexing. Note I re

	What happens is when a document is indexed, it breaks it into unique trigrams, and then finds a 
	bloom filter where it will be stored with a target bit density. If the document has a small amount 
	of trigrams it ends up in a smaller bloom filter of say 256 bits, and if larger it goes into a 
	larger one. This is done to avoid over filling the filters, which drives up the false positive rate,
	or under filling them and wasting memory.

	When the full 64 documents have been added to a bucket then in the case of a 512 bit bloom filter another 512 
	int64's are appended on the end, and then those are filled right to left.

	Where shards represent a different bloom filter size, say 512 of 2048 bits, and buckets exist as a 
	single uint64 slice in a shard. They are split out logically here to help understanding.
						</aside>
					</section>
					<section>
						<h2>Copy the shards after indexing</h2>
						<p>Result? Less fragmented memory, faster search.</p>
<pre><code style="font-size: 14px; line-height: 1em;">bloomFilter = append(ci.bloomFilter, make([]int64, 512)...)

// attempt to save/organise memory shrink lists... https://go.dev/blog/slices-intro#TOC_6
out := make([]int64, len(bloomFilter))
copy(out, bloomFilter)
bloomFilter = out
</code></pre>
					</section>
					<section>
						<h2>Frequency Concious Bloom Filter</h2>
						<p>Rare terms need more hashes to reduce false positive rate</p>

<pre><code style="font-size: 14px; line-height: 1em;">func (ci *CaissonIndex) DetermineHashCount(ngram string) int {
	// version 0.1
	// if nothing that indicates its a very rare term so it needs the most hashes
	// so set that up as the default
	hashCount := 5

	v, ok := ci.termTreatments[ngram]
	if ok {
		weight := float64(v) / float64(ci.highestTermCount) * 100

		if weight >= 10 {
			hashCount = 1
		} else if weight >= 5 {
			hashCount = 2.5
		} else if weight >= 2 {
			hashCount = 3
		} else if weight >= 1.5 {
			hashCount = 4
		}
	}

	return hashCount
}
</code></pre>
					</section>

					<section>
						<h2>Result?</h2>
						<p>Wasted time... For trigrams anyway</p>
						<p>New algorithm is mind blowing.</p>
<pre><code style="font-size: 14px; line-height: 1em;">func DetermineHashCount(ngram string) int {
	return 2
}
</code></pre>
						<aside class="notes">
Amazing I know. I found this out by testing different hash counts from 1 to 10 against the frequency ones
against a dozen different sized bloom filters looking for the lowest false positive rate.

In almost every case 2 worked out to give the best possible signal to noise ratio. I suspect this is due to
trigrams being fairly common across all code with none being particiually unique unlike natural language.
						</aside>
					</section>

					<section>
						<h2>Restrict Parallelism</h2>
						<p>Parallelism works... if you have CPU to spare</p>
<pre><code style="font-size: 14px; line-height: 1em;">var sem = make(chan bool, 5) // counting semaphore

func doSearch() { // only 5 instances of this function can run
	sem <- true
		defer func() {
		<- sem
	}()

	// Do CPU/Memory intensive stuff here
}
</code></pre>
						<aside class="notes">
This one seems counter intuitive. 

But the thing is when it comes to processes that are really pushing system limits, doing things in serial
to an extent can be faster. 

For search, imagine each query takes one second. Process in parallel and if 10 requests come in, they all
get a result 10 seconds later. Do it in serial and one user gets it in 1 second, the second in 2 etc.. to 10.

This is where I really like Go functionality. I remember writing a counting semaphore in C# once and it was
a horrible bug ridden thing. To have something so simple in Go using using channels is amazing language design.
						</aside>
					</section>
					<section>
						<h2>Searching: Done per shard</h2>
						<p>I find this algorithm beautifully simple.</p>
<pre><code style="font-size: 14px; line-height: 1em;">func Search(queryBits []uint64) []int {
	var results []int
	var res uint64

	for i := 0; i < len(bloomFilter); i += 2048 {
		res = bloomFilter[queryBits[0]+uint64(i)]

		for j := 1; j < len(queryBits); j++ {
			res = res & bloomFilter[queryBits[j]+uint64(i)]

			if res == 0 { // important! skip shard if nothing!
				break
			}
		}

		if res != 0 {
			for j := 0; j < 64; j++ {
				if res&(1<&lt;j) > 0 {
					results = append(results, 64*(i/2048)+j)
				}
			}
		}

	}

	return results
}
</code></pre>
						<aside class="notes">
With the index done we can now search.
					
The core search algorithm is as follows. 

I find this algorithm beautifully simple. We take in query positions for the search, so in the case of searching for "searchcode" we turn that into trigrams
then hash them using the same hash functions to get 6+ uint64's from 0 to whatever the filter is configured to be in a slice.

Then, walk over each logical block or bucket, which is as many uint64's as exist in the bloom filter, and then logically & that against the previous one. 
If its 0 bail out, otherwise if we have finished record the documentid based on what its position in the index is.


Whats really cool about this is that we jump potentially all of the bytes in a block if we hit that res == 0 condition quickly, avoiding us walking any memory at all! This is the state we want
to hit as often as possible.

Results when returned gives ids, which we can then use the idToFile to find the true id for this document. 

Once we have these id its a matter of reaching out to our primary data store, pulling back the documents and processing from there.
	</aside>
					</section>
					<section>
						<h2>Searching: Visually</h2>
						<p>Perform & between each row, and if we see 0 skip to next bucket</p>
						<img src="./img/bloomsearch.gif" height="500px" style="border: none;" /><br>
					</section>

					

					<section>
						<h2>Grand Total Result</h2>
						<p>Rolling average index search time: ~50ms</p>
						<p>140,000,000 to 180,000,000 files</p>
						<p>~100GB RAM</p>
						<img src="./img/searchtime.png" style="border: none;" />


<pre><code style="font-size: 14px; line-height: 1em;">{
    "level": "info",
    "totalCount": 266,
    "falseCount": 144,
    "positiveCount": 122,
    "timeMillis": 24,
    "reductionPercent": 0.4586466165413534,
    "query": "while (*d++ = *s++); source:github repo:linux",
    "time": "2023-11-08T06:30:19+01:00",
    "message": "search"
}</code></pre>

					</section>
				</section>
					
				<section>
					<h2>Conclusions</h2>
					<p>Go. I doubt I could have done it in another language. I still don't like nil checks.</p>
					<p>Bloomfilters + Trigrams works well. As far as I know this is globally unique. Nobody else I know uses this approach.</p>
					<p>Dealing with false positives from the filters isnt a deal breaker due to trigrams.</p>
					<aside class="notes">As you can see its a short bit of code. Only about 150 lines. I really encourage you to have a look and play with it.</aside>
				</section>

				<section>
					<h2>Thank You!</h2>
					<p>Probably nobody cases how searchcode works, but I care, and I know. Now you do too.</p>
					<img src="./img/gopher.png" height="500px" style="border: none;" /><br>
					<a href="https://searchcode.com/">https://searchcode.com/</a><br>
					<a href="https://boyter.org/posts/how-i-built-my-own-index-for-searchcode/">https://boyter.org/posts/how-i-built-my-own-index-for-searchcode/</a><br>
					<a href="https://boyter.org/">https://boyter.org/</a>
					<aside class="notes">
Of course... probably nobody using searchcode probably cares that its running on a unique bloom filter trigram
backed index with ideas borrowed from bing. Even if I am fairly sure this is the only instance of any search engine doing so.

But I know... and now you do too.

Now if you want one of these great looking stickers designed in house at Kablamo, 
come talk to myself or anyone else at the Kablamo desk and get one. Feel free to tell me 
all the mistakes I made too.
					</aside>
				</section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
