<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>GopherConSyd 2023</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1>Bloom Filters: Building a Cutting Edge Go Search Engine to Explore the World's Source Code</h1>
					<aside class="notes">
Good morning Sydney!
Lovely to see everyone back for day two.
Hope you are all caffinated and comfortable.
As you can mostly see im talking about bloom filers and search. Sorry about the clickbait title, but you gotta stand out in the 
paper selection process somehow.
					</aside>
				</section>

				<section>
					<section>
						<h2>Who are you?</h2>
						<p>
						"Officially" technical lead/principle at Kablamo but a "code monkey" at heart.</p>
						<p>I blog <a href="https://boyter.org/">boyter.org</a> I free software <a href="https://github/boyter/">github/boyter/</a> I run <a href="https://searchcode.com/">searchcode.com</a> also on the twitter.com <a href="https://twitter.com/boyter">@boyter</a> activitypub <a href="https://honk.boyter.org/boyter">@boyter@honk.boyter.org</a></p>
						<aside class="notes">
So who am I? 
I am not going to bore you too much with who I am because you probably don't care. 
Im not famous, but you can find me at these places.
						</aside>
					</section>
					<section>
						<h2>https://boyter.org/</h2>
						<p>Everything is <a href="https://boyter.org/">here</a>, so feel free to go back to sleep</p>
						<img src="./img/halflisten.jpg" height="500px;" style="border: none;" />
						<aside class="notes">
For those who prefer to hang out on slack everything you are about to see is now available boyter.org
Don't worry too much about missing anything.
You can even skip ahead on the slides and head off for a coffee if you like. I won't judge you.
						</aside>
					</section>
				</section>

				<section>
					<section>
						<h2>PHP -> Python -> Java -> Go</h2>
						<p><a href="https://searchcode.com/">searchcode.com</a></p>
						<img src="./img/searchcode.gif" height="500px;" style="border: none;" />
						<aside class="notes">
So I run searchcode.com which as the imaginative name would suggest searches over source code. 
I have been doing this for the last 10 years modifying and rewriting it from PHP to Python to 
Java and finally to Go.

Its a serious side project, where I get to have a wonderful time with it playing with algorithms, 
and data structures. It gets enough traffic to make it this interesting, 
with several million requests hitting it a day so I can try these things at some level of scale.

Its a great testing ground where I can fail without too many problems. Yes I do fail a lot with it.

It indexes about 75 billion lines of code across 40 million projects.

Incidently there has been a lot of talks about the importance of tests here so far.
searchcode is very light on tests.
It does however get enough traffic that I can say "Thank you internet for testing it for me!".
						</aside>
					</section>
					<section>
						<h2>The index</h2>
						<p>My personal shame</p>
						<img src="./img/sphinx_manticore.png" style="border: none;" />
						<aside class="notes">
But most of the time I have worked on it there was one constant, which was the index, provided using Sphinx
early on and later a forked version of Sphinx called Manticore.

Both are fantastic pieces of sofware, but I was abusing them in ways beyond the creators intents and it 
was causing uptime issues. Searches were taking 10's of seconds, it was consuming all the CPU 
and memory on the box and it was no longer a good solution. 

Also I had been feeling a bit like a fraud, how can I claim to be a search guy without 
using my own index. So early in 2020, I decided I would build my own.

Of course the first step was to doing anything is to boast about it to everyone, 
so I informed the work slack channel, some friends
and the wife who is of course contractually obligated to listen to everything I say.

She responded with "thats nice".
						</aside>
					</section>
					<section>
						<p>early termination, syntax highlighting, matching, snippet extraction, 
rate limiting, <strong>index</strong>, bot detection, ranking, distributed algorithms, caching, tokenization,
string searching, regular expressions, data structures, line detection, CPU cache lines, duplicate detection, 
literal extraction, unicode, case insensitive matching etc...</p>
<aside class="notes">
Here are some of the things that go into any search engine.

Every part you see is one of those problems you lightly scratch and discover
people getting PhD's in. So it constantly keeps me interested and learning.

While all of them are facinating in some way I am limiting myself to just the index today.
					</aside>
					</section>
				</section>

				<section>
					<h2>Considerations</h2>
					<ul>
						<li>Free service
							<ul>
								<li>Put everything in RAM</li>
								<li>Downtime not a huge issue</li>
								<li>Single server</li>
								<li>Single binary, no daemons!</li>
							</ul>
						</li>
						<li>Boolean queries</li>
 						<li>Single developer, time constrained</li>
					</ul>
					<aside class="notes">
So we are building our own index.

Now we need to consider the goals of searchcode.
Firstly its free service... this influences the design, because I don't need to worry about pesky customers.
As such downtime is not a problem, if it goes for a while no big issue.
I want it to run on a single server, again downtime isnt important and it makes maintenance easier.
When it comes to search.
Turns out most people just type terms and expect results, VERY few people actually do boolean queries.
The code needs to be understandable by me... this is where Go is really useful.
Also I rewrote the site in Go and wanted to ship a single binary that does everything.

Lastly, and this is for you, this is how I built an index, not necessarily how you should build one.
					</aside>
				</section>

				<section>
					<section>
							<h2>Searching: Tokenisation</h2>
							<p>Mapping / Stemming</p>
	<code style="font-size: 18px; line-height: 1em;">
"searchcode"         -> [searchcode]
"sydney gophercon"   -> [sydney, gophercon]
"likes liked likely" -> [like]
	</code>
	<p>Does not work for code!</p>
	<code style="font-size: 18px; line-height: 1em;">for(i=0;i++;i&lt;100)</code>
							<aside class="notes">
So one thing I need to cover is tokenisation. This is where you convert text into something you can index.
Generally tokenisation is splitting on space characters you find in text.
But can get more complex.
Space splitting doesnt work on east asian languages for example.
This does not work for code either and if you want to search for i++ in the middle of code thats valid
and should work.
							</aside>
					</section>
					<section>
						<h2>Searching code: Tokenisation</h2>
						<p>Trigrams</p>
						<small>This works for east asian languages too</small>
<code style="font-size: 18px; line-height: 1em;">"searchcode"   -> [sea, ear, arc, rch, chc, hco, cod, ode]
"pppppppppppp" -> [ppp]
</code>
						<aside class="notes">
You can solve this problem by splitting on trigrams, this is where you break the text apart into characters of 3 
and index those. 

One catch with this is that you get false positives, some inputs generate the same 
trigrams despite being different. You also have terms with low cardinality such 
as repeated characters in a line. So the letter p repeated 100 times is no more useful than 3 of them. 
They produce the same trigram.
						</aside>
					</section>
					<section>
						<h2>Problems</h2>
						<p>Creates long posting lists</p>
						<p>Introduces false positives</p>
<code style="font-size: 18px; line-height: 1em;">"searchcode" -> [searchcode]</code>
						<p>vs</p>
<code style="font-size: 18px; line-height: 1em;">"searchcode" -> [sea, ear, arc, rch, chc, hco, cod, ode]
</code>
						<aside class="notes">
Trigrams have their own problems.
If we tokenise by trigrams we get a great deal more tokens we need to index. In our example 
searchcode turns into 8 terms we need to add to our index, vs a single thing we would need if we treated
it as plain space delimited text. This is an important consideration, because it enlarges the index a great deal.
						</aside>
					</section>
					<section>
						<h2>Trigram Generation<h2>
<code style="font-size: 14px; line-height: 1em;">func Trigrams(text string) []string {
	var runes = []rune(text)

	if len(runes) <= 2 {
		return []string{}
	}

	ngrams := make([]string, len(runes)-2)

	for i := 0; i < len(runes); i++ {
		if i+3 < len(runes)+1 {
			ngram := runes[i : i+3]
			ngrams[i] = string(ngram)
		}
	}

	return ngrams
}
</code>
					<aside class="notes">
So here is some code to create trigrams given some input text.

Interesting fact, this is by far the single biggest bottleneck in searchcode when indexing.
If someone wants to profile and improve performance on it I would really appreciate it. 
It dominiates the indexing profile by a huge amount.</aside>
					</section>
					<section>
						<img src="./img/nerdsniped.png" style="border: none;" />
						<aside class="notes">
	Consider yourself nerd sniped.
						</aside>
					</section>

				</section>
			

				<section>
					<section>
						<h2>What is an index?</h2>
						<p>Structured list. Keys point at data so searches are faster.</p>
						<p>Given a term, return id's which contain it.</p>
						<aside class="notes">
So what is an index. The definition can be a little fuzzy, but I am defining it for me as a 
function that I pass in a term or terms and it returns a list of integers
which refer to documents that likely contain those terms, possibly ordered by relevance.
						</aside>
					</section>
					<section>
						<h2>Textbook 101 index</h2>
						<p>2 examples, positional and non-positional</p><code style="font-size: 14px; line-height: 1em;">package main

func main() {
	// non-positional index
	index := map[string][]int{} 
	index["gopher"] = append(index["gopher"], 1337)

	// positional index
	type pos struct {
		id  int   // unique document id
		loc []int // store document positions in posting list
	}
	posIndex := map[string][]pos{} 
	posIndex["gopher"] = append(posIndex["gopher"], pos{1337, []int{1, 2, 3, 99}})
}
</code>

						<aside class="notes">
So here is the textbook 101 example.
Given a term in this case "gopher" lets index it. 

The first index here is a non positional index. Its just a map of string to slice of integers.
Strings are the terms and integers the document ids.

The document id's slice are known as a posting list.
So "gopher" is found inside document 1337 here.

The next example is a positional index.
A positional index is one that stores where the term was found in the document. 

So "gopher" in document 1337 was found in positions 1, 2, 3 and 99.

Positional indexes are really useful for phrase searches and ranking.
One catch with this is that your index tends to becomes as large or larger than the thing you are indexing.
						</aside>
					</section>
					<section>
						<h2>Problem: Intersect two lists</h2>
						<p>Trigrams create LONG posting lists, need to skip list</p>
						<img src="./img/assvogel.gif" height="500px;" style="border: none;" />
						
						<aside class="notes">
The problems start when the lists become large.

Consider the search for "the assvogel". "The" is a very common word, and appears in nearly every document.
"Assvogel" is very rare and only appears in a few.

To get documents that match we need to find the intersection of the posting lists.

To get the intersection of them you have to walk each posting list looking for matching id's.
This takes a long time for the longer lists.

This gets worse when you add more common terms to the query, or you add more documents.

To solve this you end up using a data structure called "skip list" to speed this process up.
						</aside>
					</section>
					<section>
						<h2>For those wondering...</h2>
						<img src="./img/vulture.jpg" style="border: none;" />
						<aside class="notes">
For those wondering.
Assvogel is an obsolete Afrikaans word for a South African vulture.
						</aside>
					</section>
					<section>
						<h2>Problem 2</h2>
						<h3>Compression</h3>
						<code style="font-size: 14px; line-height: 1em;">index := map[string][]int{} // this should be compressible right?</code>
						<p>Shannon Elias Fano</p>
						<img src="./img/elias_fano.png" style="border: none;" />
						<aside class="notes">
The second problem is memory usage. It looks like the posting lists could be compressed.

Compressing them is a good idea because they take a lot of space, and we want the index in RAM.

Shannon Elias Fano compression is a technique used to compress a sorted list of integers.

Don't worry you arent expected to understand how it works.
						</aside>
					</section>
					<section>
						<h2>Complexity</h2>
						<code style="font-size: 16px; line-height: 1em;">index := map[string][]int{} // non-positional index
</code>
<p>vs</p>
						<img src="./img/complex.png" style="border: none;" />
						<aside class="notes">
This introduces complexity.
This is clearly a lot more complex than what we started with. 
We need to build a CompressedSkipList.
						</aside>
					</section>
					<section>
						<h2>My attempt</h2>
						<p>Two turkeys taped together does not make an eagle.</p>
						<img src="./img/turkeys.jpg"  height="500px;" style="border: none;" />
						<aside class="notes">
This is what my attempted looked like.

So I did attempt to create a CompressedSkipList.

I implemented both the skip list and elias fano compression, and got two turkeys taped together.
Not the eagle I wanted. Thats on me, no Go.

So I rethought my approach. How about bitsliced signatures?
						</aside>
					</section>
					
				</section>

				<section>
					<section>
						<h2>How about bloom filters?</h2>
						<p>A.K.A Bitsliced signatures</p>
						<aside class="notes">
There is a technique to search using bloom filters. However it helps if you know what one is.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Empty</h2>
						<p>16 boolean's in an array</p>
	<img src="./img/BloomFilter1.png" style="border: none;" />
						<aside class="notes">
So what is a bloom filter.
In short a space efficent probablistic data structure.

You add items, and can check if it was added. 

They never return false negatives, but they do occassionaly lie and report something being added when it was not.

So lets look at this example,

We have a 16 bit bloom filter. Its just a slice of booleans set by default to false, indicated by 0 here.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Add</h2>
						<p>Hash the term 3 times and set the bits</p>
	<img src="./img/BloomFilter2.png" style="border: none;" />
						<aside class="notes">
To add something to the filter we get a term, hash it multiple times using a integer returning hash like fnv, 
and use the resulting
outputs to map to bit positions inside our filter. We then set those positions to true.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Add second</h2>
						<p>3 more bits set</p>
	<img src="./img/BloomFilter3.png" style="border: none;" />
						<aside class="notes">
We add another term. Same process, hash 3 times and set the bits.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Add overlapping bits</h2>
						<p>"big" and "dog" share 2 bits</p>
	<img src="./img/BloomFilter4.png" style="border: none;" />
						<aside class="notes">
Another term added, where 2 of the bits overlap. This is an expected property of the filter
and one of the ways they are space efficient.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Hit</h2>
						<p>hash "big" and check bits</p>
	<img src="./img/BloomFilter5.png" style="border: none;" />
						<aside class="notes">
To check if the filter has something we do the same process. Hash the term as we did on insert,
then check the bit positions. They are all true so this indicates big was probably added to the filter.
Why probably? We will get to that in a moment.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: Miss</h2>
						<p>one bit position is 0 so miss</p>
	<img src="./img/BloomFilter7.png" style="border: none;" />
						<aside class="notes">
Another check, but notice that the middle bit is false. This means we know that sydney was never added
to this filter.
						</aside>
					</section>
					<section>
						<h2>Bloom filter: False Positive</h2>
						<p>"big" and "yellow" supplied bits</p>
	<img src="./img/BloomFilter6.png" style="border: none;" />
						<aside class="notes">
Lastly we see an example of a false positive match. We hash and check the positions and they are all true.
But we never added this term, the bits were supplied by other terms.

Now while bloom filters do introduce false positives, remember we have to deal with them anyway 
since trigrams produce the same problem.

You will find that a lot of tweaking of bloom filters is to control the false positive rate.
						</aside>
					</section>

					<section>
						<h2>Go Bloom Filter</h2><code style="font-size: 14px; line-height: 1em;">package main

import (
	"fmt"
	"hash/fnv"
)

func main() {
	bloom := make([]bool, 16)          // 16 bit bloom filter
	hash := func(term string) uint64 { // single hash function for bloom filter
		hsh := fnv.New64()
		_, _ = hsh.Write([]byte(term))
		return hsh.Sum64() % uint64(len(bloom))
	}

	bloom[hash("gopher")] = true // add to the filter
	bloom[hash("sydney")] = true

	for _, i := range bloom { // print out the filter
		if i == true {
			fmt.Print("1")
		} else {
			fmt.Print("0")
		}
	}

	if bloom[hash("sydney")] == true { fmt.Print("\nprobably added") }
	if bloom[hash("house")] == false { fmt.Print("\nwas not added") }
	if bloom[hash("boyter")] == true { fmt.Print("\nfalse positive! was never added!") }
}
</code><code style="font-size: 14px; line-height: 1em;">$ go run main.go 
0010000001000000
probably added
was not added
false positive! was never added!
</code>

						<aside class="notes">
So here is a bloom filter implemented in go. The filter itself is 4 lines of code. A slice of booleans,
a function to hash and thats all you need. The output shows that terms were added, and a false positive.
						</aside>
					</section>

					<section>
						<h2>Bloom filter: search</h2>
					
						<p>Check bit positions 1 and 7. Document 4 matches.</p>
						<code style="font-size: 14px; line-height: 1em;">for each bloomfilter
	for each bit
		check if bit location in filter is set
	if all matching bits are set
		record possible match</code>

						<img src="./img/bloom_naieve_search.gif" height="400px" style="border: none;" />

						<aside class="notes">
So how to search over out bloom filter index? 

You just add more bloom filters.

This represents 4 documents each with their own 8 bit bloom filter. 

So to search we hash out search terms, which come to position 1 and 7. 
We loop over each filter, checking the bit positions at 1 and 7.
If any are false we know it cannot be a match.
If all are true we have a possible match. In this case document 4.
						</aside>
					</section>
				</section>

				<section>
					<section>
						<h2>Advantages</h2>
						<ul>
							<li>Compressed. Only using several bits per term!</li>
							<li>Very simple!!!!
								<ul>
								<li>Adding</li>
								<li>Editing</li>
								<li>Searching</li>
								<li>Extensible</li>
								</ul>
							</li>
						</ul>
						<aside class="notes">
Bloom filters searches have a lot going for them. They are compressed by nature, using a few bits per term added.
They are also really simple to implement as you just saw, its only 5 lines of code.
Adding is simple, just add a new filter.
Editing is simple, just fiddle some values or replace the filter.
Searching is a really simple for loop.
You can extend them to counting bloom filters, or put structs for positions.
						</aside>
					</section>
					<section>
						<h2>Problems</h2>
						<p>No free lunch...</p>
<code style="font-size: 14px; line-height: 1em;">package main
			
import (
	"fmt"
	"runtime"
)

func main() {
	memUsage := func() string {
		var m runtime.MemStats
		runtime.ReadMemStats(&m)
		return fmt.Sprintf("%v MB", m.Alloc/1024/1024)
	}

	fmt.Println(memUsage())
	bigBloom := make([]bool, 100_000_000) // represents lots of bloom filters in memory
	fmt.Println(memUsage())
	_ = len(bigBloom)
}
</code><code style="font-size: 14px; line-height: 1em;">$ go run main.go
0 MB
95 MB</code>
						<aside class="notes">
There are of course problems.

Firstly.

How much memory does 100 million bools take up? Almost 100 MB which if you calculate is about 8x what you expect.

This program shows the issue nicely.

Problem is that each "bit" in this uses 1 byte under the hood.
Not a problem with Go it occurs in any other major language.
						</aside>
					</section>
					<section>
						<h2>Problem 2</h2>
						<p>Generic RAM stick</p>
						<img src="./img/ram.jpg" height="500px" style="border: none;" />
						<aside class="notes">
Another problem is that is that this search is slow... This comes down to how fetching bits out of 
memory works.

When you probe a single bit on most modern sysems you actually pull back 512 bits from RAM. This is because a 
full cache line is read. So its a 512 times overhead just to test a single bit! 

As a result on average you end up walking ALL the memory for your filter, depending on which bits your probe.

This is one one of the reasons this as an approach fell out of favor in the 70's, because in practice
you do end up walking all the addressable memory.
						</aside>
					</section>
					<section>
						<h2>Illustration</h2>
						<img src="./img/2048_bloom_2.png"  style="border: none;" />
						<aside class="notes">
Here is a representation of the issue. We have a 2048 bit bloom filter, where each square is a bit.
We have hashed our terms to match 6 bit positions.

We used a good hash function so we get a decent distribution within those locations and now want to probe those
bits.
						</aside>
					</section>
					<section>
						<h2>Can we do better?</h2>
						<img src="./img/2048_bloom_3.png" style="border: none;" />
						<aside class="notes">
Because the bits are all within 512 bits of each other, we are likely to pull the entire filter across 
the CPU.

This is a big problem because accessing memory often isnt as fast as you expect. Modern CPU's can theoretically 
push more than 100 GB across the CPU per second.

In theory theory and practice are the same. In practice they arent.

In reality you are more likely to get 50 GB. So if your index is 100 GB in size
you are limited to 1 search every two seconds. 

Can we do better?
						</aside>
					</section>
				</section>

				
				

				<section>
					<section>
						<h2>Bitfunnel</h2>
						<p>Good enough for Dan Luu? Good enough for you.</p>
						<img src="./img/bitfunnel.png" style="border: none;" />
						<aside class="notes">
In 2017 at SIGIR this paper about bitfunnel was released, detailing how bing uses
bit signatures or bloom filters to power its fresh index.

It won best paper at SIGIR, which is probably the most prestigious IR conferences.

The thing that got my attention is that Dan Luu is a co-author. Anything he writes I pay attention to.
Hence my personal saying "Good enough for Dan Luu, Good enough for you."
						</aside>
					</section>
					<section>
							<h2>Fixes</h2>
							<p>Rotate the filter. Documents now on columns not rows.</p>
							<img src="./img/rotate.gif" height="500px" style="border: none;" />
							<aside class="notes">
In the 80's a smart person called Roberts noticed you could rotate the filter, 
assuming each filter has the same exact size.

So we do that by turning the rows into columns. So each row used to represent a document, 
but now each column does. Filled right to left.
		</aside>
					</section>

					<section>
						<p>Fetch row 1 and 7 same as previous example</p>
						<img src="./img/rotate3.png" height="500px" style="border: none;" />
						<aside class="notes">
With this done we only need to inspect the rows containing the bit positions of the query. 

So like our previous search we are checking bit postitions 1 and 7 which are now rows 1 and 7.
						</aside>
					</section>
					<section>
						<p>Logically & all rows</p>
						<img src="./img/rotate4.png" height="500px" style="border: none;" />
						<aside class="notes">
We then logically & them together and keep the result.

The nice thing about this is that a AND in the CPU is close to being a free operation from a performance 
point of view.
In fact the computation for this is so low it becomes all about the memory lookups.
						</aside>
					</section>
					<section>
						<p>Pos 1 is true, so document 4 matches</p>
						<img src="./img/rotate5.png" height="500px" style="border: none;" />
						<aside class="notes">
So in this particular case, we see a single bit is left on in the first position with 
corresponds to document 4.
This is because we filled right to left, based on our rotation.
						</aside>
					</section>
					<section>
						<h2>Results?</h2>
						<p>This reduces the amount of RAM we need to access by a huge factor for larger bloom filters.</p>
						<aside class="notes">
The result of this is it reduces memory access by a huge amount. Something like 200x.
						</aside>
					</section>

					<section>
						<h2>Pack the bits with bit set</h2>
						<p>Use int64's to hold the filters in columns, and flip bits starting right to left.</p>
<code style="font-size: 14px; line-height: 1em;">var bloomFilter []uint64
var bloomSize = 16
var currentBlockDocumentCount = 0
var currentBlockStartDocumentCount = 0

func Add(item []bool) error {
	if currentBlockDocumentCount == 0 || currentBlockDocumentCount == 64 {
		bloomFilter = append(bloomFilter, make([]uint64, bloomSize)...)
		currentBlockDocumentCount = 0
		currentBlockStartDocumentCount += bloomSize
	}

	for i, bit := range item {
		if bit {
			bloomFilter[currentBlockStartDocumentCount+i] |= 1 << currentBlockDocumentCount
		}
	}

	currentBlockDocumentCount++
	currentDocumentCount++

	return nil
}
</code>
					<aside class="notes">
The next step is to continue to save space.

So lets write code to pack our filters. This code packs one bloom filter at a time into an int64 slice
right to left, and once hitting document 65 adds more ints to the slice so we can continue adding documents.

As a result to add documents we need only turn them into trigrams, hash those into a normal bloom filter,
and pass them into this. Very simple from a code perspective.
					</aside>
					</section>




					<section>
						<h2>Result</h2>
						<p>16 bit bloom filter, with 32 documents added. Less wasted space.</p>
<code style="font-size: 14px; line-height: 1em;">0000000000000000000000000000000010100011111111111111111111111101
0000000000000000000000000000000001110000000000010000100000000000
0000000000000000000000000000000000000000000000000000000000000000
0000000000000000000000000000000000100011111100000000000000000000
0000000000000000000000000000000000100000000000000000000000000000
0000000000000000000000000000000011000000000000000000000000000000
0000000000000000000000000000000000000000000000000000000000000000
0000000000000000000000000000000000001000000000000001000000000000
0000000000000000000000000000000000111100000000000000000000000000
0000000000000000000000000000000000100001111100000001010101011110
0000000000000000000000000000000010000010000010001010101010100011
0000000000000000000000000000000001011000000000000000000000000000
0000000000000000000000000000000001101011111111111111111111111111
0000000000000000000000000000000000110000001000000001100000001000
0000000000000000000000000000000010100010000111111110101010100001
0000000000000000000000000000000001100011111100000000000000000000
</code>
						<aside class="notes">
This is what it looks like in memory after adding 32 documents. We have a 16 bit bloom filter, 
with 16 int64's one after the other.
We have added 32 documents to it, so only the right most 32 bits have anything set. 

This ensures we are optimally using the space. Because we pack 64 documents into each 
int we end up using a single bit per location in the bloom filter. No 8x overhead!

It also becomes very fast to iterate this in code because its a simple for loop over a slice. 

It also means when we do our & operation we are now searching 64 documents for every operation, which is a huge speed up.
	</aside>
					</section>
			
					<section>
						<h2>Sharding</h2>
						<p>Shard based on the length of the document we want to index.</p>
<code style="font-size: 14px; line-height: 1em;">0000000100000000 // underfilled bloom filter
1011111111111110 // overfilled bloom filter</code>
						<p>Result? Less wasted space. Squeeze every bit.</p>
<code style="font-size: 14px; line-height: 1em;">
┌──────────────────┐   ┌──────────────────┐   ┌──────────────────┐
│      index       ├─┬▶│  shard 512 bits  ├┬─▶│  block-1 64 docs │
└──────────────────┘ │ └──────────────────┘│  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     ├─▶│  block-2 64 docs │
                     │                     │  └──────────────────┘
                     │                     │                      
                     │                     │  ┌──────────────────┐
                     │                     └─▶│  block-3 64 docs │
                     │                        └──────────────────┘
                     │                                            
                     │                                            
                     │ ┌──────────────────┐   ┌──────────────────┐
                     └▶│  shard 1024 bits ├┬─▶│  block-1 64 docs │
                       └──────────────────┘│  └──────────────────┘
                                           │                      
                                           │  ┌──────────────────┐
                                           └─▶│  block-2 64 docs │
                                              └──────────────────┘
</code>
						<aside class="notes">
However the fix is still a little wasteful because smaller documents don't need large bloom filters.

So we shard on the document length, where larger documents are added to larger bloom filters.

What happens is when a document is indexed, it broken into unique trigrams, and allocated 
bloom filter thats size is appropiate to keep a certain bit density. 

This is done to avoid over filling the filters, which drives up the false positive rate,
or under filling them and wasting memory.

This sort of represents how things look in memory.

Shards have a different bloom filter size, say 512 or 1048 bits, and all blocks exist as a 
single int slice in a shard. Each block contains 64 documents, but all exist in a single slice.
						</aside>
					</section>
					<section>
						<h2>Copy the shards after indexing</h2>
						<p>Result? Less fragmented memory, faster search.</p>
<code style="font-size: 14px; line-height: 1em;">// attempt to save/organise memory shrink lists... https://go.dev/blog/slices-intro#TOC_6
out := make([]int64, len(bloomFilter))
copy(out, bloomFilter)
bloomFilter = out
</code>
						<aside class="notes">
So when you are working with really large slices, and you constantly append to them, like searchcode does you can 
get a great deal of value copying it over itself with a new slice you allocate up front.

The result is less memory fragmentration, which in our case means a faster search.
						</aside>
					</section>
					<section>
						<h2>Frequency Concious Bloom Filter</h2>
						<p>Rare terms need more hashes to reduce false positive rate</p><code style="font-size: 14px; line-height: 1em;">func (ci *CaissonIndex) DetermineHashCount(ngram string) int {
	// version 0.1
	// if nothing that indicates its a very rare term so it needs the most hashes
	// so set that up as the default
	hashCount := 5

	v, ok := ci.termTreatments[ngram]
	if ok {
		weight := float64(v) / float64(ci.highestTermCount) * 100

		if weight >= 10 {
			hashCount = 1
		} else if weight >= 5 {
			hashCount = 2.5
		} else if weight >= 2 {
			hashCount = 3
		} else if weight >= 1.5 {
			hashCount = 4
		}
	}

	return hashCount
}
</code>
						<aside class="notes">
In bitfunnel one of the thing they implemented was Frequency Concious Bloom Filters.
The reason for this is terms like "the" appear in almost every document. So you can get away with
false positive matches on it, because its likey it was in the document anyway. 
However "assvogel" appears in almost none so you want more hashes to drive
its false positive rate down.

Dont overthink it, just remember rarer terms need more hashes.

This is an early prototype function I had for it... I itereated on this more than I care to admit.
						</aside>
					</section>

					<section>
						<h2>Result?</h2>
						<p>Wasted time... For trigrams anyway</p>
						<p>New algorithm is mind blowing.</p>
<code style="font-size: 14px; line-height: 1em;">func DetermineHashCount(ngram string) int {
	return 2
}
</code>
						<aside class="notes">
The result was a lot of wasted time actually.

I found this out by testing different fixed hash counts from 1 to 10 against the frequency concious ones
against a dozen different sized bloom filters looking for the lowest false positive rate over after indexing
several million lines of code.

In almost every case 2 hashes worked out to give the best possible signal to noise ratio. I suspect this is due to
trigrams being fairly common across all code with none being particiually unique unlike natural language.
						</aside>
					</section>

					<section>
						<h2>Restrict Parallelism</h2>
						<p>Parallelism works... if you have CPU to spare</p>
<code style="font-size: 14px; line-height: 1em;">var sem = make(chan bool, 5) // counting semaphore

func doSearch() { // only 5 instances of this function can run
	sem <- true
		defer func() {
		<- sem
	}()

	// Do CPU/Memory intensive stuff here
}
</code>
						<aside class="notes">
This one seems counter intuitive. 

But the thing is when it comes to processes that are really pushing system limits, doing things in serial
to an extent can be faster for users. 

Imagine each query takes one second. Process in parallel and if 10 requests come in, they all
get a result 10 seconds later. Do it in serial and one user gets it in 1 second, the second in 2 etc.. to 10.

This is where I really like Go functionality. I remember writing a counting semaphore in C# once and it was
a horrible bug ridden thing. To have something so simple in Go using using channels just speaks to  
amazing language design.
						</aside>
					</section>
					<section>
						<h2>Searching</h2>
						<p>The core loop.</p>
<code style="font-size: 14px; line-height: 1em;">func Search(queryBits []uint64) []int {
	var results []int
	var res uint64

	for i := 0; i < len(bloomFilter); i += 2048 {
		res = bloomFilter[queryBits[0]+uint64(i)]

		for j := 1; j < len(queryBits); j++ {
			res = res & bloomFilter[queryBits[j]+uint64(i)]

			if res == 0 { // important! skip shard if nothing!
				break
			}
		}

		if res != 0 {
			for j := 0; j < 64; j++ {
				if res&(1<&lt;j) > 0 {
					results = append(results, 64*(i/2048)+j)
				}
			}
		}

	}

	return results
}
</code>
						<aside class="notes">
The core search loop.

I find this algorithm beautifully simple.
				
We take in query positions for the search, so in the case of searching for "searchcode" we turn that into trigrams
then hash them using the same 2 functions to get 16 ints's from 0 to 2048 in this case.

Then, walk over each logical block of 2048 integers, and then logically & each row we are looking at. 
If we see all zeros we bail out, and skip to the next block of 2048. 

If we don't have all zeros we extract the bits set and use that to determine the document id.

Whats really cool about this is that we jump potentially an entire blocks of 2048 ints if we hit that res == 0 condition quickly, 
avoiding us looking at most of the memory! 
This is the state we want to hit as often as possible, and when we do we skip up to 16,384 bytes at a time.

Results when returned gives ids, which we can then use to get the document itself for further processing.

The best part is that this is a simple for loop over a slice of ints, and as we all know for loops go brrrr
	</aside>
					</section>
					<section>
						<img src="./img/brr.png" height="500px" style="border: none;" /><br>
						<aside class="notes">
						</aside>
					</section>
					<section>
						<h2>Searching: Visually</h2>
						<p>Perform & between each row, and if we see 0 skip to next block</p>
						<img src="./img/bloomsearch.gif" height="500px" style="border: none;" /><br>
						<aside class="notes">
Visually the search looks a bit like this. Where it pulls back rows, 
logically anding them and moving to the 
next before jumping to the next block, or skipping ahead where it finds nothing.
						</aside>
					</section>

					

					<section>
						<h2>Final Result</h2>
						<p>Rolling average index search time: ~50ms</p>
						<p>140,000,000 to 180,000,000 files - roughly 75 billion lines</p>
						<p>Index rougly ~100GB RAM</p>
						<img src="./img/searchtime.png" style="border: none;" />

						<aside class="notes">
So whats the final result?
So right now the average search time for the index is about 50 milliseconds. 
This is from the seconds I was getting previously, and a massive improvement improving the service.
This is generally over 140 to 180 million files, this changes depending on whats being indexed, due to 
duplicate code detections and minfied file checks.
The index aims to be 100 GB in size.

You can actually see how long any search took by looking at the source where it will print out 
the time taken to do everything to render the page.

This is not as fast as the times reported by bitfunnel, but they are using highly optimised C++,
they don't deal with trigrams, have some additional tricks they implemented, and most importantly
 actually know what they are doing

						</aside>

					</section>
				</section>
					
				<section>
					<h2>Conclusions</h2>
					<p>Go. I doubt I could have done it in another language.</p>
					<p>Bloomfilters + Trigrams works well. As far as I know this is globally unique. Nobody else I know uses this approach.</p>
					<p>A minimal version is available for you to play with <a href="https://github.com/boyter/indexer">https://github.com/boyter/indexer</a></p>
					<aside class="notes">
So conclusions.
I doubt I could have done this in another language. 
I like Go. I don't love it, it doesnt push the happy parts of my brain the way Python for example does.
But it just gets out of the way, and while I want to hurt myself every time I write another err nil check...
I realise I solved the problem... fairly quickly... the solution is solid and understandable and I just move on.
I guess that fits in with the boring that Go seems to aim for. Absolute success there.

The other is that Bloomfilters + Trigrams work really well. I actually asked chatgpt about this and it suggested
I shouldn't use them. 
Its also as far as I know unique approach with nobody having tried it before. Although nobody
in the search space really talk about what they are doing.

I have also uploaded a minimal version of everything for you to download and play around with.
					</aside>
				</section>

				<section>
					<p>Users probably don't care how searchcode's index works, but I know. Now you do too.</p>
					<img src="./img/gopher.png" height="500px" style="border: none;" /><br>
					<aside class="notes">


Of course... probably nobody using searchcode cares very much that its running on a unique bloom filter trigram
backed index with ideas borrowed from bing. 

But I know... and now you do too.

Thank you very much. Ill be at the Kablamo booth with the lovely stickers if you want to chat.
					</aside>
				</section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
